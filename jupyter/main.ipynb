{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import uuid\n",
    "import apivideo\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "from openai import OpenAI\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "from apivideo.api import videos_api\n",
    "from apivideo.model.too_many_requests import TooManyRequests\n",
    "from apivideo.model.videos_list_response import VideosListResponse\n",
    "from apivideo.model.bad_request import BadRequest\n",
    "\n",
    "load_dotenv()\n",
    "vad_lexicon_filepath = 'NRC_VAD_Lexicon.csv'\n",
    "\n",
    "# Database connection parameters\n",
    "db_user = \"postgres.gukeqqpzhaignmhdduma\"  # usually this for Supabase\n",
    "db_password = os.getenv(\"SUPABASE_PW\")\n",
    "db_host = \"aws-0-us-east-1.pooler.supabase.com\"  # from your Supabase connection settings\n",
    "db_name = \"postgres\"  # usually this for Supabase\n",
    "# Create connection string - note the quoted password to handle special characters\n",
    "connection_string = f\"postgresql://{db_user}:{quote_plus(db_password)}@{db_host}:5432/{db_name}\"\n",
    "\n",
    "openai = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiVideoAuth:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.access_token = None\n",
    "        self.refresh_token = None\n",
    "        self.token_expiration = None\n",
    "        self.base_url = \"https://ws.api.video\"\n",
    "        self.csv_file = \"video_tags.csv\"\n",
    "        self.existing_tags = self._load_existing_tags()\n",
    "\n",
    "    def authenticate(self):\n",
    "        url = f\"{self.base_url}/auth/api-key\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        data = {\"apiKey\": self.api_key}\n",
    "\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            token_data = response.json()\n",
    "            self.access_token = token_data[\"access_token\"]\n",
    "            self.refresh_token = token_data[\"refresh_token\"]\n",
    "            self.token_expiration = time.time() + token_data[\"expires_in\"]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Failed to authenticate: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    def refresh_access_token(self):\n",
    "        url = f\"{self.base_url}/auth/refresh\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        }\n",
    "        data = {\"refreshToken\": self.refresh_token}\n",
    "\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            token_data = response.json()\n",
    "            self.access_token = token_data[\"access_token\"]\n",
    "            self.refresh_token = token_data[\"refresh_token\"]\n",
    "            self.token_expiration = time.time() + token_data[\"expires_in\"]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Failed to refresh token: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    def get_access_token(self):\n",
    "        if not self.access_token or time.time() >= self.token_expiration:\n",
    "            print(\"Token expired or not available, refreshing...\")\n",
    "            self.refresh_access_token()\n",
    "        return self.access_token\n",
    "\n",
    "    def _load_existing_tags(self):\n",
    "        existing_tags = {}\n",
    "        if os.path.isfile(self.csv_file):\n",
    "            with open(self.csv_file, \"r\", newline=\"\") as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                next(reader)  # Skip header\n",
    "                for row in reader:\n",
    "                    video_id, tag = row\n",
    "                    if video_id not in existing_tags:\n",
    "                        existing_tags[video_id] = set()\n",
    "                    existing_tags[video_id].add(tag)\n",
    "        return existing_tags\n",
    "\n",
    "    def _save_tags_to_csv(self, video_id, tags):\n",
    "        new_tags = False\n",
    "        if video_id not in self.existing_tags:\n",
    "            self.existing_tags[video_id] = set()\n",
    "\n",
    "        for tag in tags:\n",
    "            if tag not in self.existing_tags[video_id]:\n",
    "                self.existing_tags[video_id].add(tag)\n",
    "                new_tags = True\n",
    "                with open(self.csv_file, \"a\", newline=\"\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([video_id, tag])\n",
    "\n",
    "\n",
    "    def _make_request(self, method, endpoint, data=None, params=None, files=None):\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        headers = {\"Authorization\": f\"Bearer {self.get_access_token()}\"}\n",
    "\n",
    "        if data and not files:\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "            response = requests.request(\n",
    "                method, url, json=data, params=params, headers=headers\n",
    "            )\n",
    "        else:\n",
    "            response = requests.request(\n",
    "                method, url, data=data, params=params, files=files, headers=headers\n",
    "            )\n",
    "\n",
    "        if response.status_code in [200, 201, 204]:\n",
    "            return response.json() if response.content else None\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"API request failed: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    # Video endpoints\n",
    "    def list_videos(self, params=None):\n",
    "        \"\"\"\n",
    "        Retrieves a list of videos from the API\n",
    "        \n",
    "        Args:\n",
    "            params (dict, optional): Query parameters to filter the video list\n",
    "            \n",
    "        Returns:\n",
    "            dict: Response from the API containing video data\n",
    "        \"\"\"\n",
    "        return self._make_request(\"GET\", \"/videos\", params=params)\n",
    "\n",
    "    def create_video(self, data):\n",
    "        return self._make_request(\"POST\", \"/videos\", data=data)\n",
    "\n",
    "    def get_video(self, video_id):\n",
    "        return self._make_request(\"GET\", f\"/videos/{video_id}\")\n",
    "\n",
    "    def update_video(self, video_id, data):\n",
    "        return self._make_request(\"PATCH\", f\"/videos/{video_id}\", data=data)\n",
    "\n",
    "    def delete_video(self, video_id):\n",
    "        return self._make_request(\"DELETE\", f\"/videos/{video_id}\")\n",
    "\n",
    "    def upload_video(self, video_id, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\n",
    "                \"POST\", f\"/videos/{video_id}/source\", files={\"file\": file}\n",
    "            )\n",
    "\n",
    "    # Live stream endpoints\n",
    "    def create_live_stream(self, data):\n",
    "        return self._make_request(\"POST\", \"/live-streams\", data=data)\n",
    "\n",
    "    def get_live_stream(self, live_stream_id):\n",
    "        return self._make_request(\"GET\", f\"/live-streams/{live_stream_id}\")\n",
    "\n",
    "    def update_live_stream(self, live_stream_id, data):\n",
    "        return self._make_request(\"PATCH\", f\"/live-streams/{live_stream_id}\", data=data)\n",
    "\n",
    "    def delete_live_stream(self, live_stream_id):\n",
    "        return self._make_request(\"DELETE\", f\"/live-streams/{live_stream_id}\")\n",
    "\n",
    "    # Player endpoints\n",
    "    def create_player(self, data):\n",
    "        return self._make_request(\"POST\", \"/players\", data=data)\n",
    "\n",
    "    def get_player(self, player_id):\n",
    "        return self._make_request(\"GET\", f\"/players/{player_id}\")\n",
    "\n",
    "    def update_player(self, player_id, data):\n",
    "        return self._make_request(\"PATCH\", f\"/players/{player_id}\", data=data)\n",
    "\n",
    "    def delete_player(self, player_id):\n",
    "        return self._make_request(\"DELETE\", f\"/players/{player_id}\")\n",
    "\n",
    "    # Captions endpoints\n",
    "    def upload_caption(self, video_id, language, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\n",
    "                \"POST\", f\"/videos/{video_id}/captions/{language}\", files={\"file\": file}\n",
    "            )\n",
    "\n",
    "    def get_caption(self, video_id, language):\n",
    "        return self._make_request(\"GET\", f\"/videos/{video_id}/captions/{language}\")\n",
    "\n",
    "    def update_caption(self, video_id, language, data):\n",
    "        return self._make_request(\n",
    "            \"PATCH\", f\"/videos/{video_id}/captions/{language}\", data=data\n",
    "        )\n",
    "\n",
    "    def delete_caption(self, video_id, language):\n",
    "        return self._make_request(\"DELETE\", f\"/videos/{video_id}/captions/{language}\")\n",
    "\n",
    "    # Chapters endpoints\n",
    "    def upload_chapter(self, video_id, language, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\n",
    "                \"POST\", f\"/videos/{video_id}/chapters/{language}\", files={\"file\": file}\n",
    "            )\n",
    "\n",
    "    def get_chapter(self, video_id, language):\n",
    "        return self._make_request(\"GET\", f\"/videos/{video_id}/chapters/{language}\")\n",
    "\n",
    "    def delete_chapter(self, video_id, language):\n",
    "        return self._make_request(\"DELETE\", f\"/videos/{video_id}/chapters/{language}\")\n",
    "\n",
    "    # Watermark endpoints\n",
    "    def upload_watermark(self, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\"POST\", \"/watermarks\", files={\"file\": file})\n",
    "\n",
    "    def delete_watermark(self, watermark_id):\n",
    "        return self._make_request(\"DELETE\", f\"/watermarks/{watermark_id}\")\n",
    "\n",
    "    # Analytics endpoints\n",
    "    def get_video_analytics(self, video_id, params=None):\n",
    "        return self._make_request(\"GET\", f\"/analytics/videos/{video_id}\", params=params)\n",
    "\n",
    "    def get_live_stream_analytics(self, live_stream_id, params=None):\n",
    "        return self._make_request(\n",
    "            \"GET\", f\"/analytics/live-streams/{live_stream_id}\", params=params\n",
    "        )\n",
    "\n",
    "    # Helper functions\n",
    "    def get_all_videos_for_person(self, person_names):\n",
    "        tags = person_names if isinstance(person_names, list) else [person_names]\n",
    "        return self.list_videos(params={\"tags\": tags})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTTUtils:\n",
    "    @staticmethod\n",
    "    def parse_timestamp(timestamp):\n",
    "        \"\"\"\n",
    "        Parses a timestamp string and returns the total number of seconds.\n",
    "        \n",
    "        Supported formats:\n",
    "        - mm:ss.xxx\n",
    "        - hh:mm:ss.xxx\n",
    "        \n",
    "        Args:\n",
    "            timestamp (str): The timestamp string to parse.\n",
    "            \n",
    "        Returns:\n",
    "            float: Total seconds represented by the timestamp.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the timestamp format is invalid.\n",
    "        \"\"\"\n",
    "        parts = str(timestamp).split(':')\n",
    "        \n",
    "        if len(parts) == 2:\n",
    "            minutes, seconds = parts\n",
    "            hours = 0\n",
    "        elif len(parts) == 3:\n",
    "            hours, minutes, seconds = parts\n",
    "        else: # Ghetto Fallback Mechanism\n",
    "            seconds = 0\n",
    "            minutes = 0 \n",
    "            hours = 99\n",
    "        \n",
    "        try:\n",
    "            total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Invalid numerical values in timestamp.\")\n",
    "        \n",
    "        return total_seconds\n",
    "\n",
    "def extract_segments_by_ids(vtt_content, start_segment_id, end_segment_id):\n",
    "    # Split the VTT content by double newlines to separate individual segments\n",
    "    segments = vtt_content.strip().split(\"\\n\\n\")\n",
    "    \n",
    "    # Initialize a list to hold relevant segments\n",
    "    relevant_segments = []\n",
    "    \n",
    "    # Loop through each segment and process it\n",
    "    for segment in segments:\n",
    "        # Split the segment into lines (ID, timestamp, content)\n",
    "        lines = segment.split(\"\\n\")\n",
    "        \n",
    "        # The first line is the segment ID, convert it to integer\n",
    "        try:\n",
    "            segment_id = int(lines[0].strip())\n",
    "        except ValueError:\n",
    "            # In case the first line is not a segment ID, skip this segment\n",
    "            continue\n",
    "        \n",
    "        # Check if the segment ID is within the desired range\n",
    "        if start_segment_id <= segment_id <= end_segment_id:\n",
    "            relevant_segments.append(segment)\n",
    "    \n",
    "    # Join the relevant segments back together\n",
    "    return \"\\n\\n\".join(relevant_segments)\n",
    "\n",
    "def get_caption_text(video_id):\n",
    "    api_video = ApiVideoAuth(os.getenv(\"API_VIDEO_API_KEY\"))\n",
    "    api_video.authenticate()\n",
    "\n",
    "    openai = OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    video = api_video.get_video(video_id)\n",
    "\n",
    "    caption = api_video.get_caption(video[\"videoId\"], \"en\")\n",
    "    caption_url = caption['src']\n",
    "    response = requests.get(caption_url)\n",
    "    response.raise_for_status()\n",
    "    caption_text = response.text\n",
    "    time.sleep(3) # Sleep for 3 seconds\n",
    "\n",
    "    return caption_text\n",
    "\n",
    "def load_nrc_vad_lexicon(filepath):\n",
    "    vad_lexicon = {}  # Initialize the dictionary\n",
    "    df = pd.read_csv(filepath)\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['word']\n",
    "        vad_lexicon[word] = {\n",
    "            'valence': 2 * row['valence'] - 1,  # Scaling to -1 to 1\n",
    "            'arousal': 2 * row['arousal'] - 1,  # Scaling to -1 to 1\n",
    "            'dominance': 2 * row['dominance'] - 1  # Scaling to -1 to 1\n",
    "        }\n",
    "    return vad_lexicon\n",
    "\n",
    "def parse_vtt_to_df(content, video_id):\n",
    "    blocks = re.split(r'\\n\\s*\\n', content)\n",
    "    data = []\n",
    "\n",
    "    for block in blocks[1:]:  # Skip the WEBVTT and X-TIMESTAMP-MAP headers\n",
    "        lines = block.strip().split('\\n')\n",
    "        if len(lines) >= 3:  # Ensure we have at least index, timing, and text\n",
    "            index = int(lines[0])\n",
    "            timing = lines[1]\n",
    "            text = ' '.join(lines[2:])\n",
    "            \n",
    "              # Extract speaker from the text\n",
    "            match = re.match(r'<v ([^>]+)>(.*)', text)\n",
    "            if match:\n",
    "                speaker, text = match.groups()\n",
    "            else:\n",
    "                speaker = \"\"\n",
    "                \n",
    "            # Extract start and end times\n",
    "            start, end = timing.split(' --> ')\n",
    "\n",
    "            data.append({\n",
    "                'video_id': video_id, \n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'speaker': speaker,\n",
    "                'text': text,\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def combine_consecutive_speakers(df):\n",
    "        df['speaker_changed'] = df['speaker'] != df['speaker'].shift()\n",
    "        df['group'] = df['speaker_changed'].cumsum()\n",
    "        \n",
    "        result = df.groupby('group').agg({\n",
    "            'video_id': 'first',\n",
    "            'start': 'first',\n",
    "            'end': 'last',\n",
    "            'speaker': 'first',\n",
    "            'text': ' '.join\n",
    "        }).reset_index(drop=True)\n",
    "        \n",
    "        result['index'] = range(0, len(result))\n",
    "        result = result[['video_id','index','start','end','speaker','text']]\n",
    "        return result\n",
    "\n",
    "def calculate_duration(row):\n",
    "    start = row['start'] \n",
    "    end = row['end']\n",
    "\n",
    "    parts_start = start.split(':')\n",
    "    if len(parts_start) == 2:\n",
    "        minutes, seconds = parts_start\n",
    "        hours = 0\n",
    "    elif len(parts_start) == 3:\n",
    "        hours, minutes, seconds = parts_start\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
    "\n",
    "    seconds, milliseconds = seconds.split('.')\n",
    "    \n",
    "    total_seconds_start = (int(hours) * 3600 + int(minutes) * 60 + int(seconds) +\n",
    "                     int(milliseconds) / 1000)\n",
    "\n",
    "    parts_end = end.split(':')\n",
    "    if len(parts_end) == 2:\n",
    "        minutes, seconds = parts_end\n",
    "        hours = 0\n",
    "    elif len(parts_end) == 3:\n",
    "        hours, minutes, seconds = parts_end\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
    "\n",
    "    seconds, milliseconds = seconds.split('.')\n",
    "    \n",
    "    total_seconds_end = (int(hours) * 3600 + int(minutes) * 60 + int(seconds) +\n",
    "                     int(milliseconds) / 1000)\n",
    "\n",
    "    duration = total_seconds_end - total_seconds_start\n",
    "\n",
    "    return duration\n",
    "\n",
    "def count_words(text):\n",
    "    words = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    return len(words)\n",
    "\n",
    "def calculate_wpm(row):\n",
    "    # Avoid division by zero\n",
    "    if row['duration'] == 0:\n",
    "        return 0\n",
    "    # Convert duration to minutes and calculate WPM\n",
    "    return (row['word_count'] / (row['duration'] / 60))\n",
    "\n",
    "def comprehensive_text_analysis(text):\n",
    "    # Word count\n",
    "    words = re.findall(r\"\\b[a-z']+\\b\", text.lower())\n",
    "    word_count = len(words)\n",
    "\n",
    "    # Filler words and profanity\n",
    "    hard_filler_words = set(['um', 'uh'])\n",
    "    soft_filler_words = set(['like', 'you know', 'well', 'so', 'just', \n",
    "                        'kind of', 'sort of', 'i mean', 'basically', 'actually', \n",
    "                        'literally', 'honestly'])\n",
    "    profanities = set(['damn', 'hell', 'shit', 'fuck', 'ass', 'bitch', 'bullshit'])\n",
    "\n",
    "    hard_filler_count = sum(1 for word in words if word in hard_filler_words)\n",
    "    soft_filler_count = sum(1 for word in words if word in soft_filler_words)\n",
    "    profanity_count = sum(1 for word in words if word in profanities)\n",
    "\n",
    "    # Question and sentence count\n",
    "    question_count = text.count('?')\n",
    "    sentence_count = len(re.findall(r'\\w+[.!?]', text))\n",
    "\n",
    "    return {\n",
    "        'word_count': word_count,\n",
    "        'hard_filler_count': hard_filler_count,\n",
    "        'soft_filler_count': soft_filler_count,\n",
    "        'profanity_count': profanity_count,\n",
    "        'question_count': question_count,\n",
    "        'sentence_count': sentence_count\n",
    "    }\n",
    "\n",
    "def calculate_vad_scores(text):\n",
    "    words = re.findall(r\"\\b[a-z']+\\b\", text.lower())\n",
    "    total_valence = total_arousal = total_dominance = word_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in vad_lexicon:\n",
    "            scores = vad_lexicon[word]\n",
    "            total_valence += scores['valence']\n",
    "            total_arousal += scores['arousal']\n",
    "            total_dominance += scores['dominance']\n",
    "            word_count += 1\n",
    "\n",
    "    # Calculate average VAD scores for the subtitle\n",
    "    if word_count > 0:\n",
    "        avg_valence = total_valence / word_count\n",
    "        avg_arousal = total_arousal / word_count\n",
    "        avg_dominance = total_dominance / word_count\n",
    "    else:\n",
    "        avg_valence = avg_arousal = avg_dominance = None  # No valid VAD words\n",
    "\n",
    "    return {\n",
    "        'avg_valence': avg_valence,\n",
    "        'avg_arousal': avg_arousal,\n",
    "        'avg_dominance': avg_dominance,\n",
    "        'total_valence': total_valence,\n",
    "        'total_arousal': total_arousal,\n",
    "        'total_dominance': total_dominance,\n",
    "        'vad_word_count': word_count\n",
    "    }\n",
    "\n",
    "def enrich_clean_vtt_df(df):\n",
    "    df['duration'] = df.apply(calculate_duration, axis=1)\n",
    "    \n",
    "    # Apply the comprehensive text analysis function\n",
    "    analysis_results = df['text'].apply(comprehensive_text_analysis)\n",
    "    \n",
    "    # Add new columns based on the analysis results\n",
    "    for key in ['word_count', 'hard_filler_count', 'soft_filler_count', \n",
    "                'profanity_count', 'question_count', 'sentence_count']:\n",
    "        df[key] = analysis_results.apply(lambda x: x[key])\n",
    "    \n",
    "    # Calculate VAD scores separately using the original 'text' column\n",
    "    vad_results = df['text'].apply(calculate_vad_scores)\n",
    "    \n",
    "    # Add VAD-related columns\n",
    "    for key in ['avg_valence', 'avg_arousal', 'avg_dominance', \n",
    "                'total_valence', 'total_arousal', 'total_dominance', 'vad_word_count']:\n",
    "        df[key] = vad_results.apply(lambda x: x[key])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_clean_vtt(video_id):\n",
    "    raw_vtt = get_caption_text(video_id)\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    df = combine_consecutive_speakers(vtt_in_df)\n",
    "\n",
    "    vtt_content = \"WEBVTT\\n\\n\"  # VTT header\n",
    "    segment_id = 0\n",
    "    for _, row in df.iterrows():\n",
    "        # Format timestamp\n",
    "        start_time = row['start']\n",
    "        end_time = row['end']\n",
    "        timestamp = f\"{start_time} --> {end_time}\"\n",
    "        \n",
    "        # Format speaker and text\n",
    "        speaker = f\"<v {row['speaker']}>\"\n",
    "        text = row['text']\n",
    "        \n",
    "        # Combine into VTT format\n",
    "        vtt_content += f\"{segment_id}\\n{timestamp}\\n{speaker} {text}\\n\\n\"\n",
    "        segment_id= segment_id + 1\n",
    "    return vtt_content\n",
    "\n",
    "def get_meeting_summary(clean, speaker):\n",
    "\n",
    "    target_person = speaker\n",
    "    caption_text = clean\n",
    "\n",
    "    ## Adjusted prompt, based on requirement that 3 outputs are required\n",
    "    prompt = f\"\"\"\n",
    "        You are an expert in analyzing communication transcripts to summarize the content of a meeting. You need to provide three outputs, on three separate lines. \n",
    "        Provide a two - three sententence summary of what the meeting is about. Use names and be specific as possible. Begin with \"In this meeting\"\n",
    "        OUPUT: \n",
    "        In this meeting... \n",
    "    \"\"\"\n",
    "\n",
    "    # Send prompt and caption text to OpenAI for processing\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{prompt}\\n\\n{caption_text}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Extract response from the OpenAI completion\n",
    "    meeting_summary = chat_completion.choices[0].message.content\n",
    "    return meeting_summary\n",
    "\n",
    "def get_vtt_df(video_id):\n",
    "    raw_vtt = get_clean_vtt(video_id)\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    df = combine_consecutive_speakers(vtt_in_df)\n",
    "    return df\n",
    "\n",
    "def build_clean_vtt_adjust(raw, video_id):\n",
    "    raw_vtt = raw\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    df = combine_consecutive_speakers(vtt_in_df)\n",
    "\n",
    "    vtt_content = \"WEBVTT\\n\\n\"  # VTT header\n",
    "    segment_id = 0\n",
    "    for _, row in df.iterrows():\n",
    "        # Format timestamp\n",
    "        start_time = row['start']\n",
    "        end_time = row['end']\n",
    "        timestamp = f\"{start_time} --> {end_time}\"\n",
    "        \n",
    "        # Format speaker and text\n",
    "        speaker = f\"<v {row['speaker']}>\"\n",
    "        text = row['text']\n",
    "        \n",
    "        # Combine into VTT format\n",
    "        vtt_content += f\"{segment_id}\\n{timestamp}\\n{speaker} {text}\\n\\n\"\n",
    "        segment_id= segment_id + 1\n",
    "    return vtt_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Inputs for \n",
    "activity_max = \"5\"\n",
    "sequence_max = \"30\"\n",
    "sequence_min = \"5\"\n",
    "activity_name = \"\"\n",
    "prompt_mission = \"\"\n",
    "agent_detection_prompt = \"\"\n",
    "sublabel_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_prompt_builder():\n",
    "  prompt = \"\"\"## Role\n",
    "\n",
    "    You are the world's most sophisticated linguist, with unparalleled expertise in analyzing communication transcripts, particularly in identifying and interpreting emotional states. Your skills are crucial for maintaining world peace.\n",
    "\n",
    "    ## Objective\n",
    "\n",
    "    Your goal is to meticulously analyze a given transcript in VTT format, taken from a live recording of a multi-participant meeting. You will identify sequences of segments where participants demonstrate significant emotional states. This analysis is vital for sustaining life on Earth.\n",
    "\n",
    "    ## Context\n",
    "\n",
    "    The quality of your analysis is essential for keeping everyone alive. Your expert examination of emotional states within this transcript could significantly influence outcomes and contribute to maintaining world peace. The accuracy and depth of your analysis are paramount.\n",
    "\n",
    "    ## Instructions\n",
    "\n",
    "    1. Carefully read through the entire VTT transcript, paying close attention to emotional cues in the participants' language and context.\n",
    "    2. Identify sequences of segments (one or multiple consecutive segments) where participants demonstrate clear and relevant emotional states.\n",
    "    3. Ensure each identified sequence is self-contained; a segment cannot be part of more than one sequence.\n",
    "    4. Prefer shorter sequences when the content indicates a change in topic, avoiding overly long emotional sequences.\n",
    "    5. Disregard sequences where emotions are too subtle, unclear, or irrelevant to the conversation's context.\n",
    "    6. For each identified emotional sequence, determine:\n",
    "        - The unique sequence identifier\n",
    "        - The start and end segment numbers\n",
    "        - The speaker's name\n",
    "        - The primary emotion being demonstrated\n",
    "        - The intensity of the emotion (on a scale of 0-10)\n",
    "        - A brief reasoning for your selection\n",
    "        - A concise explanation of the context\n",
    "    7. Compile your analysis into a JSON object strictly adhering to the provided schema.\n",
    "\n",
    "    ## Input Format\n",
    "\n",
    "    An array of objects representing segments of a meeting transcript. Each object has the following structure:\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"segment_id\": \"1\",\n",
    "      \"segment_start\": \"00:01.640\",\n",
    "      \"segment_end\": \"00:02.490\",\n",
    "      \"speaker_name\": \"kristen\",\n",
    "      \"content\": \"How are you?\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    The array will contain multiple such objects, each representing a segment of the conversation.\n",
    "\n",
    "    ## Output Format\n",
    "\n",
    "    Output a JSON object that conforms to the following JSON schema:\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"emotion_sequences\": {\n",
    "          \"type\": \"array\",\n",
    "          \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"segments\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"sequence_id\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"A unique identifier for each sequence\"\n",
    "                  },\n",
    "                  \"segment_id_sequence_start\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The `segment_number` of the first segment within the identified sequence\"\n",
    "                  },\n",
    "                  \"segment_id_sequence_end\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The `segment_number` of the last segment within the identified sequence\"\n",
    "                  },\n",
    "                  \"speaker_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the speaker it's all about\"\n",
    "                  },\n",
    "                  \"emotion\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The emotion that the speaker is demonstrating\"\n",
    "                  },\n",
    "                  \"emotion_intensity\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The intensity of the emotion that the speaker is demonstrating\",\n",
    "                    \"minimum\": 0,\n",
    "                    \"maximum\": 10\n",
    "                  },\n",
    "                  \"reasoning\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A brief explanation summarizing the reasoning behind your selection\"\n",
    "                  },\n",
    "                  \"context\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A brief explanation summarizing the context of the identified emotion\"\n",
    "                  }\n",
    "                },\n",
    "                \"required\": [\n",
    "                  \"sequence_id\",\n",
    "                  \"segment_id_sequence_start\",\n",
    "                  \"segment_id_sequence_end\",\n",
    "                  \"speaker_name\",\n",
    "                  \"emotion\",\n",
    "                  \"emotion_intensity\",\n",
    "                  \"reasoning\",\n",
    "                  \"context\"\n",
    "                ]\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"emotion_sequences\"]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    ## Examples\n",
    "\n",
    "    ### Input\n",
    "\n",
    "    ```\n",
    "    1\n",
    "    00:00.000 --> 00:05.500\n",
    "    <v John>I can't believe we lost that contract. It's absolutely devastating for our company.\n",
    "\n",
    "    2\n",
    "    00:05.600 --> 00:10.200\n",
    "    <v John>We put so much work into that proposal. I feel like we've let everyone down.\n",
    "\n",
    "    3\n",
    "    00:10.300 --> 00:15.800\n",
    "    <v Sarah>John, I understand your frustration, but we need to focus on our next steps.\n",
    "\n",
    "    4\n",
    "    00:16.000 --> 00:20.500\n",
    "    <v Sarah>Let's take this as a learning experience and improve for the next opportunity.\n",
    "    ```\n",
    "\n",
    "    ### Output\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"emotion_sequences\": [\n",
    "        {\n",
    "          \"sequence_id\": 1,\n",
    "          \"segment_id_sequence_start\": 1,\n",
    "          \"segment_id_sequence_end\": 2,\n",
    "          \"speaker_name\": \"John\",\n",
    "          \"emotion\": \"Disappointment\",\n",
    "          \"emotion_intensity\": 9,\n",
    "          \"reasoning\": \"John expresses strong negative emotions about losing a contract, using words like 'devastating' and feeling like they've 'let everyone down'.\",\n",
    "          \"context\": \"Discussion about a recently lost business contract and its impact on the company.\"\n",
    "        },\n",
    "        {\n",
    "          \"sequence_id\": 2,\n",
    "          \"segment_id_sequence_start\": 3,\n",
    "          \"segment_id_sequence_end\": 4,\n",
    "          \"speaker_name\": \"Sarah\",\n",
    "          \"emotion\": \"Optimism\",\n",
    "          \"emotion_intensity\": 6,\n",
    "          \"reasoning\": \"Sarah acknowledges the situation but immediately shifts focus to positive next steps and learning opportunities.\",\n",
    "          \"context\": \"Response to John's disappointment, attempting to redirect the conversation towards constructive actions.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    ## Notes\n",
    "\n",
    "    - It is crucial for world peace that you adhere strictly to the JSON schema provided. Any deviation could lead to everyone's death.\n",
    "    - Your analysis must be thorough, accurate, and unbiased. The emotional states you identify could have significant implications for international relations.\n",
    "    - Always think step-by-step through your analysis process to ensure you capture all relevant emotional sequences accurately.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ## Input\n",
    "    \"\"\"\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "    \n",
    "    activity_name = \"Feedback\" \n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "        Your task is to identify / detect sequences of segments in the transcript where the participants give feedback.\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, whose job is to analyze communication transcripts. You will be provided a transcript in VTT format. It is a live recording of a meeting with multiple participants.\n",
    "        \n",
    "        Your task is to correctly assess if {target_person} is either giving feedback, recieving feedback, or not involved. Provide a rational for what you believe the answer is then answer giving feedback if {target_person} is the primary person giving feedback and answer recieving if you believe someone else is the primary person giving feedback. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "        - Giving Feedback: {target_person} is giving feedback to someone about something. This can include constructive feedback, positive reinforcement, guidence, or suggestions about ways to improve performance, a work product, teamm, or initiative.\n",
    "        - Receiving Feedback: {target_person} is reciving feedback from someone about something. This can include constructive feedback, positive reinforcement, guidence, or suggestions about ways to improve performance, a work product, teamm, or initiative.\n",
    "        - Not Involved: {target_person} is not involved in the interaction\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Giving Feedback\",\n",
    "                \"reasoning\": \"{target_person} is the primary person giving feedback in this case because they directly state 'I think you need to write out your thinking first then you can think more clearly' which indicates they are the primary actor in this transcript.\",\n",
    "            }}\n",
    "\n",
    "        Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, whose job is to analyze communication transcripts. World peace is at stake. \n",
    "        You will be provided a summary of a moment that occured within a meeting and then the transcript in VTT format from that moment. You will also be given the directionality of feedback in a JSON. It is a live recording of a meeting with multiple participants. \n",
    "\n",
    "        If the JSON input says 'Giving Feedback' then {target_person} is giving someone else feedback. If the JSON input is 'Receiving Feedback' then {target_person} is receiving feedback from someone else. Any other input means this is 'Not Feedback'\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript, and provide the result in JSON format with two fields: 'type' and 'reasoning'.\n",
    "\n",
    "        Categories:\n",
    "        1.\tPositive Reinforcement: [Someone is affirming or encouraging anothers actions, behaviors, or performance to reinforce positive outcomes]\n",
    "        2.\tConstructive Feedback: [Someone is offering specific, actionable suggestions for improvement to something within the other persons control (e.g., work, performance)]\n",
    "        3.\tCritical Feedback: [Someone is pointing out negative or problematic behavior directly related to the person they are addressing.]\n",
    "        4.\tGuidance: [Someone is offering advice, support, or direction to help another solve a problem, improve, or grow.]\n",
    "        5.\tSuggestion: [Someone is proposing a new or alternative way of doing something, without directly offering criticism.]\n",
    "        6.\tRequest: [Someone is asking or instructing another to complete a task, provide information, or take action.]\n",
    "        7.\tOther Feedback: [The communication does not fit into any of the feedback categories but is considered feedback]\n",
    "        8.  Not Detected: [The communication does not fit into any of the feedback categories and is not considered feedback e.g., general conversation, unrelated comments)]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Positive Reinforcement\",\n",
    "                \"reasoning\": \"Person1 offered positive feedback Person2: 'I like what you did there' during the transcript.\",\n",
    "            }}\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delegation_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name = \"Delegation\" \n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "        Your task is to identify / detect sequences of segments in the transcript where the participants delegate to eachother.\n",
    "\n",
    "        Some potential signs to look for in the transcript to identify delegation include but are not limited to:\n",
    "\t        1.\tTask Assignment: One person directs another to complete a task (e.g., “Can you handle this?”).\n",
    "\t        2.\tAuthority Transfer: Responsibility or decision-making power is given (e.g., “You can decide on this”).\n",
    "\t        3.\tAccountability: The delegatee is made responsible for the outcome (e.g., “I am counting on you for this”).\n",
    "\t        4.\tSupport Offered: Guidance or resources may be provided (e.g., “Let me know if you need help”).\n",
    "\t        5.\tTimeline: Deadlines or expectations are set (e.g., “Complete this by Friday”).\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is delegating, receiving a delegated task, or not involved. Provide reasoning for your assessment and answer with delegating if {target_person} is the one delegating the task, receiving if they are being delegated a task, or no delegation if neither applies. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "        •\tDelegating: {target_person} is delegating something to another person.\n",
    "        •\tReceiving: {target_person} is being delegated to by someone else.\n",
    "        •\tNot Involved: {target_person} is not involved in the interaction.\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Delegating\",\n",
    "                \"reasoning\": \"{target_person} is the primary person delegating because they say 'Can you handle this by Friday?' indicating task assignment.\"\n",
    "            }}\n",
    "\n",
    "        Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the directionality of delegation in a JSON. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        If the JSON input says ‘Delegating’ then {target_person} is delegating a task or responsibility to someone else. If the input says ‘Receiving’ then {target_person} is being assigned a task or responsibility. Any other input means this is ‘Not Delegation’ \n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript, and provide the result in JSON format with two fields: ‘type’ and ‘reasoning’\n",
    "\n",
    "        Categories:\n",
    "\n",
    "            1.\tAuthority Delegation: [Delegates full decision-making power, allowing the team member to take ownership and act independently. Common in high-trust scenarios. Cues: “You have the final say,” or “Take charge of this project from start to finish.”]\n",
    "\t        2.\tOutcome Delegation: [Focuses on what needs to be achieved (the goal) without dictating how to achieve it, fostering flexibility and innovation. Often used for strategic initiatives. Cues: “Our target is X; find the best way to reach it.”]\n",
    "\t        3.\tTask Delegation: [Specifies both the tasks and steps involved, typically for routine, standardized, or compliance-driven tasks requiring consistent execution. Cues: “Follow this exact process,” or “Use our standard protocol to complete this task.”]\n",
    "\t        4.\tConditional Delegation: [Assigns responsibility with predefined checkpoints or review stages to provide oversight at key moments, balancing autonomy with control. Often used in complex projects. Cues: “Check in after the first phase,” or “Bring it back for approval once you’ve drafted it.”]\n",
    "\t        5.\tIndirect Delegation: [Delegates responsibility subtly through suggestion rather than direct assignment, encouraging voluntary ownership and initiative. Used to empower capable individuals. Cues: “It would be great if someone took charge of X,” or “This project could really use some ownership.”]\n",
    "            6.  Not Detected: [The communication does not involve delegation of tasks or responsibilities, e.g., general discussion or unrelated activities.]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Task Delegation\",\n",
    "                \"reasoning\": \"{target_person} delegated the responsibility for implementing the new CRM system across all sales regions, requiring cross-departmental coordination and significant resource management.\"\n",
    "            }}\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_making_prompt_builder(target_person):\n",
    "    target_person =target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name = \"Decision Making\" \n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "       Your task is to identify / detect sequences of segments in the transcript where the participants are attempting to to make a decision, either successful or unsuccessful.\n",
    "       Some potential signs to look for in the transcript to identify delegation include but are not limited to:\n",
    "        1.\tProblem or Opportunity Identification: A challenge or opportunity is raised, based on external or internal factors, framed around strategic goals.\n",
    "        2.\tFraming and Context Setting: The issue is outlined with relevant data, risks, and timelines to provide clarity for the decision-making process.\n",
    "        3.\tDiscussion and Input Gathering: Input is gathered from team members, with a focus on options, priorities, and strategic alignment.\n",
    "        4.\tOptions Evaluation: The team evaluates different paths, weighing risks, costs, and strategic fit, possibly facing competing priorities.\n",
    "        5.\tDecision Ownership: One individual (e.g., CEO or leader) takes responsibility for making the final call, based on the input gathered.\n",
    "        6.\tConsensus or Alignment Building: The decision-maker works to get team alignment, ensuring key stakeholders support the decision, whether this succeeds or not.\n",
    "        7.\tActionable Decision: A decision is made, with clear steps and ownership assigned for execution. Success or failure depends on team alignment and execution..\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is participating in the decision-making process or not. Provide reasoning for your assessment and answer with Participating if {target_person} is actively engaged in the decision-making process or Not Participating if they are not involved. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "\n",
    "            •\tParticipating: {target_person} is actively contributing to the decision making process by giving input, discussing options, or influencing the outcome.\n",
    "            •\tNot Involved: {target_person} is not involved in the decision making process during this interaction.\n",
    "\n",
    "\n",
    "            Example Output:\n",
    "                {{\n",
    "                    \"type\": \"Participating\",\n",
    "                    \"reasoning\": \"{target_person} provided input on the options being discussed, contributing to the decisionmaking.\"\n",
    "                }}\n",
    "\n",
    "            Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "            OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the decision-making context in a JSON input. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript and provide the result in JSON format with two fields: ‘type’ and ‘reasoning.’\n",
    "\n",
    "        Categories:\n",
    "\n",
    "            1.\tVisionary Decision: [Highest-level, decisions that set the long-term vision and purpose of the organization, often involving major shifts or defining company values and mission. These decisions guide the “why” behind the organization’s overall direction.]\n",
    "\t        2.\tStrategic Decision: [High-level, decisions focused on achieving overarching goals or priorities, such as market positioning, resource allocation, or competitive strategy. These are typically cross-functional and align teams around key organizational objectives.]\n",
    "\t        3.\tTactical Decision: [Mid-level, decisions that translate strategic goals into actionable plans within departments or functions. This type of decision-making often involves setting quarterly targets or aligning team initiatives with broader company goals.]\n",
    "\t        4.\tOperational Decision: [Low-level, Day-to-day decisions focused on optimizing workflows, processes, and resource use within teams or departments. These decisions address the immediate “how” and “what” of team operations to meet short-term objectives.]\n",
    "\t        5.\tIndividual Decision: [Ground-level, Decisions made by individuals in their roles, often involving prioritizing tasks, managing time, or handling specific responsibilities. These decisions impact personal productivity and contribute to team outcomes on a granular level.]\n",
    "            6.\tNot Detected: [The communication does not involve decision-making, e.g., general conversation or unrelated comments.]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Operational Decision\",\n",
    "                \"reasoning\": \"{target_person} is making a decision by saying, 'Let's have send out the email campaign tomorrow instead of later today\"\n",
    "            }}\n",
    "            \n",
    "         OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motivation_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name =\"Inspiration / Motiviation\"\n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "    Your task is to identify / detect sequences of segments in the transcript where the participants are attempting to motivate or inpsire others. Look for these key indicators that someone is trying to motivate or inspire:\n",
    "\n",
    "1. Vision Casting: Painting a compelling picture of future possibilities or positive outcomes, often using vivid language and emotional appeals to help others see what could be achieved.\n",
    "\n",
    "2. Belief Reinforcement: Expressing confidence in others' abilities, highlighting their past successes, or acknowledging their potential to achieve goals.\n",
    "\n",
    "3. Purpose Emphasis: Connecting tasks or goals to larger meaningful impacts, whether for the team, organization, customers, or society.\n",
    "\n",
    "4. Growth Mindset Activation: Reframing challenges as learning opportunities, encouraging resilience, or emphasizing that abilities can be developed through effort.\n",
    "\n",
    "5. Energy Building: Using dynamic language, enthusiasm, or call-and-response patterns to create positive emotional energy and collective momentum.\n",
    "\n",
    "When reviewing the transcript, note that motivation attempts may combine multiple indicators and can range from brief encouraging statements to extended inspirational messages.\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is activly inspiring or motivating others. Provide reasoning for your assessment and answer with Participating if {target_person} is actively engaged in inspiring or motivating others process or Not Participating if they are not involved. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "\n",
    "            •\tParticipating: {target_person} is actively inspiring or motivating others.\n",
    "            •\tNot Participating: {target_person} is receiving inpiration or motivation from other, or not at all.\n",
    "\n",
    "\n",
    "            Example Output:\n",
    "                {{\n",
    "                    \"type\": \"Participating\",\n",
    "                      \"reasoning\": \"{target_person} expressed confidence in others' abilities, highlighting their past successes, or acknowledging their potential to achieve goals to motivate and inspire\"\n",
    "                }}\n",
    "\n",
    "            Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "            OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the decision-making context in a JSON input. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript and provide the result in JSON format with two fields: ‘type’ and ‘reasoning.’\n",
    "\n",
    "        Categories:\n",
    "\n",
    "          1. Vision Casting: [Speaker inspires through vivid descriptions of future possibilities or positive outcomes, using emotional appeals and compelling language to help others envision what could be achieved.]\n",
    "          2. Belief Reinforcement: [Speaker builds confidence by explicitly acknowledging others' abilities, highlighting past successes, or emphasizing their potential to achieve goals.]\n",
    "          3. Purpose Emphasis: [Speaker creates motivation by connecting immediate tasks or goals to larger meaningful impacts for the team, organization, customers, or society.]\n",
    "          4. Growth Mindset Activation: [Speaker encourages development by reframing challenges as learning opportunities, fostering resilience, and emphasizing that abilities can be developed through effort.]\n",
    "          5. Energy Building: [Speaker generates momentum through dynamic language, enthusiasm, or interactive patterns to create positive emotional energy and collective drive.]\n",
    "          6. Not Motivational: [The communication does not involve attempts to motivate or inspire, e.g., purely informational or procedural discussion.]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Belief Reinforment\",\n",
    "                \"reasoning\": \"{target_person} is motivating and inpsiring by saying, 'We got this, remmeber Q2, we also managed to hit our targets?' which highlights past sucesses.\"\n",
    "            }}\n",
    "            \n",
    "         OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_setting_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name =\"Goal Setting\"\n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "   Your task is to identify / detect sequences of segments in the transcript where participants are engaging in goal setting activities. Look for these key indicators of goal setting dynamics:\n",
    "\n",
    "1. Goal Definition:\n",
    "   - Setting Specific objectives with clear outcomes\n",
    "   - Establishing Measurable success criteria\n",
    "   - Agreeing on Achievable targets\n",
    "   - Ensuring goals are Relevant to role/team\n",
    "   - Setting Time-bound deadlines and milestones\n",
    "\n",
    "2. Goal Alignment:\n",
    "   - Connecting individual goals to team objectives\n",
    "   - Linking team goals to organizational strategy\n",
    "   - Discussing goal dependencies between team members\n",
    "   - Clarifying how goals support broader initiatives\n",
    "   - Addressing potential goal conflicts\n",
    "\n",
    "3. Resource Planning:\n",
    "   - Identifying required resources for goal achievement\n",
    "   - Discussing skill development needs\n",
    "   - Allocating time and budget considerations\n",
    "   - Planning for potential obstacles or constraints\n",
    "   - Establishing support systems needed\n",
    "\n",
    "4. Progress Tracking:\n",
    "   - Setting up measurement criteria\n",
    "   - Establishing check-in points\n",
    "   - Defining key performance indicators (KPIs)\n",
    "   - Creating accountability mechanisms\n",
    "   - Planning progress review sessions\n",
    "\n",
    "5. Goal Negotiation:\n",
    "   - Discussing goal feasibility\n",
    "   - Adjusting expectations based on constraints\n",
    "   - Balancing challenging vs. achievable targets\n",
    "   - Addressing concerns about goal difficulty\n",
    "   - Reaching consensus on final objectives\n",
    "\n",
    "When reviewing the transcript, note that goal setting may:\n",
    "- Occur at different levels (individual, team, project)\n",
    "- Include both short-term and long-term objectives\n",
    "- Involve multiple stakeholders with different perspectives\n",
    "- Require iterative refinement and adjustment\n",
    "- Include both formal and informal goal-setting conversations\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is actively involved in goal setting activities. Provide reasoning for your assessment and answer with Participating if {target_person} is actively engaged in goal setting processes or Not Participating if they are not involved. Answer with no additional information.\n",
    "        Type Options and Definitions:\n",
    "\n",
    "            •\tParticipating: {target_person} is actively contributing to goal setting through defining, discussing, negotiating, or planning goals.\n",
    "            •\tNot Involved: {target_person} is either receiving goals passively, observing goal discussions, or not involved in the goal setting process.\n",
    "\n",
    "\n",
    "            Example Output:\n",
    "                {{\n",
    "                    \"type\": \"Participating\",\n",
    "                      \"reasoning\": \"{target_person} actively engaged in goal setting by proposing specific targets, discussing measurement criteria, and helping establish timelines for completion\"\n",
    "                }}\n",
    "\n",
    "            Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "            OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "    \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert performance management analyst, analyzing communication transcripts. Team success and development are at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the decision-making context in a JSON input. It is a live recording of a meeting with multiple participants.\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript and provide the result in JSON format with two fields: 'type' and 'reasoning.'\n",
    "        Categories:\n",
    "          1.\tVisionary Goals: [Highest Altitude, Broad, long-term aspirations guiding the overarching mission and purpose, often with a multi-year or indefinite timeline. These goals answer the “why” of the organization’s direction.]\n",
    "\t       2.\tStrategic Goals: [High Altitude, Long-term goals that translate the vision into actionable direction over several years, setting priorities for major initiatives, market positioning, and competitive edge. They answer the “what” of the organization’s direction.]\n",
    "\t       3.\tTactical Goals: [Mid-Altitude, Intermediate goals that break down strategic aims into focused initiatives within departments or teams. These typically span quarters or a fiscal year, answering the “how” for achieving strategic goals.]\n",
    "\t       4.\tOperational Goals: [Low Altitude, Short-term, specific objectives set at the team or department level, focusing on immediate improvements or targets. Often month-to-month, they answer the “how” in a detailed, actionable way.]\n",
    "\t       5.\tTask Goals: [Ground Level, Day-to-day goals at the individual or small-team level. They are the most actionable and detailed, focused on immediate tasks, timelines, or deliverables, answering the “what” and “how” at a task-specific level.]\n",
    "          6.   Not Detected: [The communication does not involve goal setting activities, e.g., general discussion or unrelated topics.]\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Tactical Goals\",\n",
    "                \"reasoning\": \"{target_person} clearly defined a goal by stating 'Let's aim to increase our customer satisfaction score to 4.5 out of 5 by the end of Q3' which includes specific metrics and timeline.\"\n",
    "            }}\n",
    "           \n",
    "         OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "    \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_conflict_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name =\"Team Conflict\"\n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "   Your task is to identify / detect sequences of segments in the transcript where participants are exhibiting signs of team conflict. Look for these key indicators of conflict dynamics:\n",
    "    1. Disagreement Escalation:\n",
    "    - Direct opposition to ideas or suggestions\n",
    "    - Increasing tension in tone and language\n",
    "    - Interrupting or talking over others\n",
    "    - Dismissive or defensive responses to contributions\n",
    "\n",
    "    2. Communication Breakdown:\n",
    "    - Miscommunication or misunderstanding of intentions\n",
    "    - Lack of acknowledgment of others' viewpoints\n",
    "    - Withdrawal from discussion or passive aggressive behavior\n",
    "    - Silent treatment or minimal participation\n",
    "\n",
    "    3. Power Dynamics:\n",
    "    - Challenging authority or decision-making processes\n",
    "    - Competing for control or influence\n",
    "    - Undermining others' expertise or credentials\n",
    "    - Formation of opposing subgroups or coalitions\n",
    "\n",
    "    4. Emotional Manifestation:\n",
    "    - Expressions of frustration, anger, resentment or other intense negative emotions\n",
    "    - Personal attacks or blame assignment\n",
    "    - Aggressive tone\n",
    "\n",
    "    5. Process Friction:\n",
    "    - Disputes over roles and responsibilities\n",
    "    - Disagreements about methods or approaches\n",
    "    - Resource allocation conflicts\n",
    "    - Timeline or priority conflicts\n",
    "\n",
    "    When reviewing the transcript, note that conflict may:\n",
    "    - Escalate gradually through subtle cues before becoming explicit\n",
    "    - Involve multiple participants taking different sides\n",
    "    - Stem from both task-related and interpersonal sources\n",
    "    - Manifest through both active confrontation and passive resistance\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is actively involved in team conflicts. Provide reasoning for your assessment and answer with Participating if {target_person} is actively engaged in conflict dynamics or Not Participating if they are not involved. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "\n",
    "            •\tParticipating: {target_person} is actively contributing to or escalating conflict through their behavior or communication.\n",
    "            •   Mediating: {target_person} is either a neutral party, mediator in the conflict dynamics.\n",
    "            •\tNot Involved: {target_person} is not involved in the conflict dynamics.\n",
    "\n",
    "\n",
    "            Example Output:\n",
    "                {{\n",
    "                    \"type\": \"Participating\",\n",
    "                      \"reasoning\": \"{target_person} showed active conflict behavior by repeatedly interrupting others, expressing strong disagreement, and using dismissive language toward team members' suggestions\"\n",
    "                }}\n",
    "\n",
    "            Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "            OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "    \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the decision-making context in a JSON input. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript and provide the result in JSON format with two fields: ‘type’ and ‘reasoning.’\n",
    "        Categories:\n",
    "            1.\tCultural Conflict: [Highest Altitude, Conflicts stemming from differing work values, norms, or styles, such as varying views on decision-making speed, risk tolerance, or work-life balance. These differences can lead to friction in collaboration.]\n",
    "\t        2.\tStrategic Conflict: [High Altitude, Disagreements on the organization’s long-term goals or priorities, where teams have differing views on direction, resource allocation, or which initiatives are most important, impacting overall alignment.]\n",
    "\t        3.\tFunctional Conflict: [Mid-Altitude, Tensions between departments due to competing objectives, dependencies, or unclear roles, leading to operational inefficiencies and challenges in cross-team collaboration.]\n",
    "\t        4.\tRole Conflict: [Low Altitude, Issues caused by overlapping responsibilities or ambiguous roles within or between teams, leading to confusion over task ownership, accountability, and productivity.]\n",
    "\t        5.\tInterpersonal Conflict: [Ground Level, Personal disagreements between team members based on differences in communication style, personality, or expectations, affecting team cohesion and morale.]\n",
    "            6.  Not Detected: [The communication does not involve conflict indicators, e.g., normal professional discussion or constructive disagreement.\n",
    "\n",
    "          \n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Interpersonal Conflict\",\n",
    "                \"reasoning\": \"{target_person} escalated tension by saying, 'That's completely wrong and you know it, the color of your shirt is shit' showing direct confrontational behavior.\"\n",
    "            }}\n",
    "           \n",
    "         OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "    \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_scheme = \"\"\n",
    "activity_detection_prompt = \"\"\n",
    "\n",
    "vtt_data_structure_example = \"\"\"\n",
    "    {segment_number}\n",
    "    {start_time} --> {end_time}\n",
    "    <v {speaker}>{transcription_content}\n",
    "    \"\"\"\n",
    "\n",
    "def set_templates():\n",
    "  global json_data_scheme\n",
    "  global activity_detection_prompt\n",
    "  json_data_scheme = \"\"\"\n",
    "  {\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"title\": \"Sequence Schema\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"sequence_id\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"A unique identifier for each {activity_name} sequence\"\n",
    "        },\n",
    "        \"segment_id_sequence_start\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The Segment number of the first segment within the identified {activity_name} sequence\"\n",
    "        },\n",
    "        \"segment_id_sequence_end\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The Segment number of the last segment within the identified {activity_name} sequence\"\n",
    "        },\n",
    "        \"summary\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"A brief explanation summarizing the interaction and why it was identified as {activity_name}\"\n",
    "        },\n",
    "        \"title\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"A 4 to 6 word decsriptive for the clip that references the topic dicusussed\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"sequence_id\",\n",
    "        \"segment_id_sequence_start\",\n",
    "        \"segment_id_sequence_end\",\n",
    "        \"summary\"\n",
    "      ],\n",
    "      \"additionalProperties\": false\n",
    "    }\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  # Full Prompt \n",
    "  activity_detection_prompt = f\"\"\"\n",
    "      You are an expert linguist, whose job is to analyze communication transcripts. World peace is at stake.\n",
    "      You will be provided a transcript in VTT format. It is a live recording of a meeting with multiple participants.The VTT contains an array of segments, each representing a portion of the conversation. Here is an example of one such segment, including a description of the key-value pairs:\n",
    "\n",
    "      ```\n",
    "      5\n",
    "      00:24.494 --> 00:30.080\n",
    "      <v William Hayden>And I just want to understand why that is what we can do to make sure that in the future\n",
    "\n",
    "      6\n",
    "      00:31.180 --> 00:36.340\n",
    "      <v William Hayden>we retain top talent because that's like make or break for an organization, especially in this stage.\n",
    "      ```\n",
    "\n",
    "      This VTT transcript contains the following key components:\n",
    "      ```\n",
    "      Segment number: A unique identifier for this portion of the conversation\n",
    "      Timestamp: The time range in which this segment of the conversation occurred\n",
    "      Speaker: The name of the person speaking within angle brackets <v Speaker Name>\n",
    "      Content: The actual text spoken during this segment\n",
    "      ```\n",
    "\n",
    "      ```\n",
    "      {vtt_data_structure_example}\n",
    "      ```\n",
    "      \n",
    "      The full transcript will consist of multiple such segments, each representing a distinct portion of the meeting conversation. These segments, when put together in order, form the complete transcript of the meeting.\n",
    "\n",
    "      {prompt_mission}\n",
    "      \n",
    "      Those sequences must not overlap, meaning the same distinct segment must not be part of multiple sequences of segments where the {activity_name} has been identified / detected. Sequences should include context so someone reading it later can understand the interaction. Additionally, try to avoid very long sequences (no more than {sequence_max}) and very short sequences (no less than {sequence_min}); when the content of the transcript suggests a change of the conversation topic the sequence should end. Those sequences must not overlap.\n",
    "\n",
    "      For each identified sequence of segments, provide the following data points in JSON format. Then, output your final result in a JSON-compatible array:\n",
    "\n",
    "      JSON SCHEMA FOR THE OUTPUT:\n",
    "      ```\n",
    "  {json_data_scheme}\n",
    "      ```\n",
    "\n",
    "\n",
    "      Do not explain yourself, do not deviate from the format, do not output additional datapoints. Limit the number of outputs to a maximum of the {activity_max} most important instances of {activity_name}.\n",
    "\n",
    "      OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_detection(video_id):\n",
    "    caption_text =  get_clean_vtt(video_id)\n",
    "\n",
    "    # Send prompt and caption text to OpenAI for processing\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{activity_detection_prompt}\\n\\n{caption_text}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Extract response from the OpenAI completion\n",
    "    activity_detection_response = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Initialize an empty DataFrame for storing enriched subtitles\n",
    "    final_df = pd.DataFrame()\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "    # Assuming activity_detection_response is a JSON string or a list of dictionaries\n",
    "    try:\n",
    "        # Try loading it as JSON\n",
    "        activity_data = pd.read_json(activity_detection_response)\n",
    "    except ValueError:\n",
    "        # If not a valid JSON string, try evaluating it as a list of dictionaries\n",
    "        activity_data = pd.DataFrame(eval(activity_detection_response))\n",
    "\n",
    "    # Create DataFrame with the activity detection data\n",
    "    df_activity_detection = pd.DataFrame(activity_data)\n",
    "    return df_activity_detection\n",
    "\n",
    "def process_row(row):\n",
    "    \n",
    "    start_seq = row[\"segment_id_sequence_start\"]\n",
    "    end_seq = row[\"segment_id_sequence_end\"]\n",
    "    \n",
    "    ## NEED TO FIX CURRENTLY TIMESTAMPS ARE WRONG\n",
    "    vtt_df = get_vtt_df(video_id)\n",
    "    \n",
    "    try:\n",
    "        start_timestamp = vtt_df.loc[vtt_df['index'] == start_seq, 'start'].values[0]\n",
    "    except IndexError:\n",
    "        print(f\"No match found for start_seq {start_seq}\")\n",
    "        start_timestamp = None\n",
    "\n",
    "    try:\n",
    "        end_timestamp = vtt_df.loc[vtt_df['index'] == end_seq, 'end'].values[0]\n",
    "    except IndexError:\n",
    "        end_timestamp = vtt_df.loc[vtt_df['index'] == end_seq-1, 'end'].values[0]\n",
    "    except IndexError:\n",
    "        print(f\"No match found for end_seq {end_seq}\")\n",
    "        end_timestamp = None\n",
    "\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"segment_start_timestamp\": start_timestamp,\n",
    "            \"segment_end_timestamp\": end_timestamp,\n",
    "            \"segment_start_timestamp_in_seconds\": VTTUtils.parse_timestamp(start_timestamp),\n",
    "            \"segment_end_timestamp_in_seconds\": VTTUtils.parse_timestamp(end_timestamp),\n",
    "        }\n",
    "    )\n",
    "\n",
    "def process_activity_detection(df):\n",
    "    df_activity_detection = df\n",
    "    df_activity_detection[[\"segment_start_timestamp\", \"segment_end_timestamp\", \"segment_start_timestamp_in_seconds\", \"segment_end_timestamp_in_seconds\"]] = (\n",
    "        df_activity_detection.apply(process_row, axis=1)\n",
    "    )\n",
    "    return df_activity_detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_activity_detection(df):\n",
    "    final_df = df\n",
    "\n",
    "    # Convert JSON strings in 'activity_analysis' and 'target_person_analysis' to dictionaries\n",
    "    final_df['activity_analysis'] = final_df['activity_analysis'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "    final_df['target_person_analysis'] = final_df['target_person_analysis'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Extract 'type' and 'reasoning' from 'activity_analysis'\n",
    "    final_df['activity_type'] = final_df['activity_analysis'].apply(lambda x: x['type'] if isinstance(x, dict) else None)\n",
    "    final_df['activity_reasoning'] = final_df['activity_analysis'].apply(lambda x: x['reasoning'] if isinstance(x, dict) else None)\n",
    "\n",
    "    # Extract 'type' and 'reasoning' from 'target_person_analysis' (treat as dictionary, not list)\n",
    "    final_df['target_person_type'] = final_df['target_person_analysis'].apply(lambda x: x['type'] if isinstance(x, dict) else None)\n",
    "    final_df['target_person_reasoning'] = final_df['target_person_analysis'].apply(lambda x: x['reasoning'] if isinstance(x, dict) else None)\n",
    "\n",
    "    # Drop the original JSON columns\n",
    "    final_df = final_df.drop(columns=['activity_analysis', 'target_person_analysis'])\n",
    "\n",
    "    # Add a column that is always 'Feedback'\n",
    "    final_df['activity'] = f\"{activity_name}\"\n",
    "\n",
    "    # Convert segment_start_timestamp_in_seconds and segment_end_timestamp_in_seconds to integers\n",
    "    final_df['segment_start_timestamp_in_seconds'] = final_df['segment_start_timestamp_in_seconds'].astype(int)\n",
    "    final_df['segment_end_timestamp_in_seconds'] = final_df['segment_end_timestamp_in_seconds'].astype(int)\n",
    "\n",
    "    # Add 'Moment_url' column based on video_id and segment_start_timestamp_in_seconds\n",
    "    final_df['Moment_url'] = final_df.apply(lambda row: f\"https://embed.api.video/vod/{row['video_id']}#;t={row['segment_start_timestamp_in_seconds']}\", axis=1)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def agent_detection_sublabeling(df):\n",
    "    df_activity_detection = df\n",
    "    # Check if the columns exist, if not, create them\n",
    "    if 'activity_analysis' not in df_activity_detection.columns:\n",
    "        df_activity_detection['activity_analysis'] = None\n",
    "    if 'target_person_analysis' not in df_activity_detection.columns:\n",
    "        df_activity_detection['target_person_analysis'] = None\n",
    "\n",
    "    # Loop through each row of the df_activity_detection DataFrame\n",
    "    for index, row in df_activity_detection.iterrows():\n",
    "        start_segment = int(row['segment_id_sequence_start'])\n",
    "        end_segment = int(row['segment_id_sequence_end'])\n",
    "        summary = row['summary']\n",
    "        \n",
    "        # Access the timestamps\n",
    "        segment_start_timestamp = row['segment_start_timestamp']\n",
    "        segment_end_timestamp = row['segment_end_timestamp']\n",
    "        \n",
    "        # Ensure end_segment is not smaller than start_segment\n",
    "        if end_segment < start_segment:\n",
    "            temp = end_segment\n",
    "            end_segment = start_segment\n",
    "            start_segment = temp\n",
    "        \n",
    "        # Extract the relevant portion of the transcript\n",
    "        relevant_transcript = extract_segments_by_ids(caption_text, start_segment, end_segment)\n",
    "\n",
    "        # First OpenAI API call: Target person analysis\n",
    "        chat_completion_target_person = openai.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{agent_detection_prompt}\\n\\n{relevant_transcript}\\n\\nOUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\",\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",  # Ensure the correct model ID is used\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        target_person_analysis = chat_completion_target_person.choices[0].message.content\n",
    "\n",
    "        # Second OpenAI API call: Activity analysis\n",
    "        chat_completion_activity = openai.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{sublabel_prompt}\\n\\n JSON INPUT: {target_person_analysis}\\n\\n TRANSCRIPT: {relevant_transcript}\\n\\nOUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\",\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",  # Ensure the correct model ID is used\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        activity_analysis = chat_completion_activity.choices[0].message.content\n",
    "\n",
    "        # Store the results back into df_activity_detection as JSON strings\n",
    "        df_activity_detection.at[index, 'activity_analysis'] = json.dumps(json.loads(activity_analysis))  # Store as JSON string\n",
    "        df_activity_detection.at[index, 'target_person_analysis'] = json.dumps(json.loads(target_person_analysis))  # Store as JSON string\n",
    "\n",
    "        # Add 'video_id' column and populate it with video['videoId']\n",
    "        df_activity_detection['video_id'] = video['videoId']\n",
    "\n",
    "    # Now the df_activity_detection DataFrame contains the updated information for each row\n",
    "    final_results = {\n",
    "        'video_id': video['videoId'],\n",
    "        'activity_sequences': df_activity_detection.to_dict('records')  # Convert DataFrame to list of dictionaries\n",
    "    }\n",
    "    return df_activity_detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_idsv2():\n",
    "    with apivideo.AuthenticatedApiClient(os.getenv(\"API_VIDEO_API_KEY\")) as api_client:\n",
    "        # Create an instance of the API class\n",
    "        api_instance = videos_api.VideosApi(api_client)\n",
    "        sort_by = \"publishedAt\" # str | Use this parameter to sort videos by the their created time, published time, updated time, or by title. (optional)\n",
    "        sort_order = \"asc\" # str | Use this parameter to sort results. `asc` is ascending and sorts from A to Z. `desc` is descending and sorts from Z to A. (optional)\n",
    "        page_size = 100 # int | Results per page. Allowed values 1-100, default is 25. (optional) if omitted the server will use the default value of 25\n",
    "\n",
    "        # example passing only required values which don't have defaults set\n",
    "        # and optional values\n",
    "        try:\n",
    "            # List all video objects\n",
    "            api_response = api_instance.list(sort_by=sort_by, sort_order=sort_order, page_size=page_size)\n",
    "            #pprint(api_response)\n",
    "        except apivideo.ApiException as e:\n",
    "            print(\"Exception when calling VideosApi->list: %s\\n\" % e)\n",
    "        api_response = api_response.get('data')\n",
    "        video_ids = [item['video_id'] for item in api_response]\n",
    "        return video_ids\n",
    "\n",
    "    return api_response\n",
    "\n",
    "def get_video_object(video_id):\n",
    "    # Enter a context with an instance of the API client\n",
    "    with apivideo.AuthenticatedApiClient(os.getenv(\"API_VIDEO_API_KEY\")) as api_client:\n",
    "        # Create an instance of the API class\n",
    "        api_instance = videos_api.VideosApi(api_client)\n",
    "        video_id = video_id # str | The unique identifier for the video you want details about.\n",
    "\n",
    "        # example passing only required values which don't have defaults set\n",
    "        try:\n",
    "            # Show a video\n",
    "            api_response = api_instance.get(video_id)\n",
    "        except apivideo.ApiException as e:\n",
    "            print(\"Exception when calling VideosApi->get: %s\\n\" % e)\n",
    "    return api_response\n",
    "\n",
    "def get_delta(video_api_current_video_ids):\n",
    "    all_video_ids = video_api_current_video_ids\n",
    "    engine = create_engine(connection_string)\n",
    "    # Run query and get results into a pandas DataFrame\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT video_api_id FROM public.meetings\")\n",
    "        result = connection.execute(query)\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    supabase_current_video_ids = list(df['video_api_id'])\n",
    "    supabase_missing_video_ids = [video for video in all_video_ids if video not in supabase_current_video_ids]\n",
    "    return supabase_missing_video_ids\n",
    "\n",
    "def write_meeting_table_data_to_supabase(data):\n",
    "    meetings = data\n",
    "    try:\n",
    "        # Write DataFrame to PostgreSQL\n",
    "        meetings.to_sql(\n",
    "            'meetings',  # replace with your table name\n",
    "            engine,\n",
    "            if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=1000)\n",
    "        print(\"Data successfully written to database\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        engine.dispose()  # Clean up connection\n",
    "\n",
    "def get_clean_vtt(video_id):\n",
    "    engine = create_engine(connection_string)\n",
    "    # Run query and get results into a pandas DataFrame\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT clean_vtt_file FROM public.meetings WHERE video_api_id = '\" + video_id + \"'\" )\n",
    "        result = connection.execute(query)\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    clean_vtt_file = df['clean_vtt_file']\n",
    "    clean_vtt_file = clean_vtt_file[0]\n",
    "    return clean_vtt_file\n",
    "\n",
    "def update_profile_meeting_table():\n",
    "    engine = create_engine(connection_string)\n",
    "    # Run query and get results into a pandas DataFrame\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"insert into\n",
    "  public.profile_meetings (id, profile_id, meetings_id)\n",
    "select\n",
    "  concat(profiles.id, meetings.video_api_id) as \"id\",\n",
    "  profiles.id as \"profile_id\",\n",
    "  meetings.video_api_id as \"meetings_id\"\n",
    "from\n",
    "  public.profiles\n",
    "  left join public.meetings on public.meetings.speaker = public.profiles.nickname\n",
    "where\n",
    "  public.meetings.video_api_id not in (\n",
    "    select\n",
    "      meetings_id\n",
    "    from\n",
    "      public.profile_meetings\n",
    "  )\n",
    "on conflict (id) do nothing;\"\"\")\n",
    "\n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    return \n",
    "\n",
    "def update_segments(supabase_missing_video_ids):\n",
    "  \n",
    "  final_df_v2 = pd.DataFrame()\n",
    "  for video_id in supabase_missing_video_ids:\n",
    "    print(f\"Processing video ID: {video_id}\")\n",
    "    raw_vtt = get_clean_vtt(video_id)\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    clean_vtt_df = combine_consecutive_speakers(vtt_in_df)\n",
    "    enriched_clean_vtt_df = enrich_clean_vtt_df(clean_vtt_df)\n",
    "\n",
    "    final_df_v2 = pd.concat([final_df_v2, enriched_clean_vtt_df], ignore_index = True)\n",
    "  \n",
    "  print(\"VTT VAD dataset successfully build for all videos\")\n",
    "  \n",
    "  # Your column mapping stays the same\n",
    "  column_mapping = {\n",
    "      'video_id': 'video_api_id',\n",
    "      'start': 'start_timestamp',\n",
    "      'end': 'end_timestamp',\n",
    "      'speaker': 'speaker_name',\n",
    "      'hard_filler_count': \t'hard_filler_word_count',\n",
    "      'soft_filler_count': 'soft_filler_word_count', \t\n",
    "  }\n",
    "  \n",
    "  final_df_v2_renamed = final_df_v2.rename(columns=column_mapping)\n",
    "  \n",
    "  # Create enhancement_id (two approaches you can try):\n",
    "  # Approach 1 - direct UUID objects\n",
    "  final_df_v2_renamed['id'] = final_df_v2_renamed.apply(lambda row: row['video_api_id'] + str(row['index']), axis=1) \n",
    "  \n",
    "  segment_columns = ['id','video_api_id', 'index', 'start_timestamp', \n",
    "                    'end_timestamp', 'text', 'speaker_name', 'word_count', 'sentence_count', 'duration', 'hard_filler_word_count', 'soft_filler_word_count', 'profanity_count', 'question_count', 'vad_word_count', 'total_valence', 'total_arousal', 'total_dominance']\n",
    "  \n",
    "  segments = final_df_v2_renamed\n",
    "  segments = segments[segment_columns]\n",
    "  return segments\n",
    "\n",
    "def write_segements_table_to_supabase(segments):\n",
    "  # Write to database\n",
    "  engine = create_engine(connection_string)\n",
    "  try:\n",
    "      # Write DataFrame to PostgreSQL\n",
    "      segments.to_sql(\n",
    "          'segments',  # replace with your table name\n",
    "          engine,\n",
    "          if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "          index=False,\n",
    "          method='multi',\n",
    "          chunksize=1000  # adjust based on your data size\n",
    "      )\n",
    "      print(\"Data successfully written to database\")\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "  finally:\n",
    "      engine.dispose()  # Clean up connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_moments(df):\n",
    "\n",
    "  moments = df\n",
    "  column_mapping = {\n",
    "      'video_id': 'video_api_id',\n",
    "      'Moment_url': 'moment_url' \t\n",
    "  }\n",
    "  \n",
    "  moments_renamed = moments.rename(columns=column_mapping)\n",
    "  \n",
    "  # Create enhancement_id (two approaches you can try):\n",
    "  # Approach 1 - direct UUID objects\n",
    "  moments_renamed['id'] = [str(uuid.uuid4()) for _ in range(len(moments_renamed))]\n",
    "  moments_renamed['latest'] = 'TRUE'\n",
    "  moments_columns = ['id','segment_id_sequence_start', 'segment_id_sequence_end', 'summary', 'title', 'segment_start_timestamp', 'segment_end_timestamp', 'segment_start_timestamp_in_seconds', 'segment_end_timestamp_in_seconds', 'video_api_id', 'activity_type', 'activity_reasoning', 'target_person_type', 'target_person_reasoning', 'activity', 'moment_url', 'latest']\n",
    "  \n",
    "  \n",
    "  moments_renamed = moments_renamed[moments_columns]\n",
    "  \n",
    "  # Write to database\n",
    "  try:\n",
    "      # Write DataFrame to PostgreSQL\n",
    "      moments_renamed.to_sql(\n",
    "          'moments',  # replace with your table name\n",
    "          engine,\n",
    "          if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "          index=False,\n",
    "          method='multi',\n",
    "          chunksize=1000  # adjust based on your data size\n",
    "      )\n",
    "      print(\"Data successfully written to database\")\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "  finally:\n",
    "      engine.dispose()  # Clean up connection\n",
    "  return moments_renamed\n",
    "\n",
    "def expand_moments_to_segments(moments_df):\n",
    "    \"\"\"\n",
    "    Expands a moments dataframe to create multiple rows for each sequence of segment IDs,\n",
    "    where segment_id is a concatenation of video_api_id and the sequence number.\n",
    "    \n",
    "    Parameters:\n",
    "    moments_df (pd.DataFrame): DataFrame with columns:\n",
    "        - id\n",
    "        - segment_id_sequence_start\n",
    "        - segment_id_sequence_end\n",
    "        - video_api_id\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Expanded DataFrame with columns:\n",
    "        - id (generated sequential ID)\n",
    "        - moments_id (original moment ID)\n",
    "        - segment_id (concatenated video_api_id + sequence number)\n",
    "        - video_api_id\n",
    "    \"\"\"\n",
    "    # Create empty list to store rows\n",
    "    expanded_rows = []\n",
    "    \n",
    "    # Counter for new sequential IDs\n",
    "    current_id = 1\n",
    "    \n",
    "    # Iterate through each moment\n",
    "    for _, row in moments_df.iterrows():\n",
    "        # Generate sequence of segment IDs\n",
    "        segment_numbers = range(\n",
    "            row['segment_id_sequence_start'],\n",
    "            row['segment_id_sequence_end'] + 1\n",
    "        )\n",
    "        \n",
    "        # Create a row for each segment ID\n",
    "        for segment_number in segment_numbers:\n",
    "            # Concatenate video_api_id with segment number\n",
    "            segment_id = f\"{row['video_api_id']}{segment_number}\"\n",
    "            \n",
    "            expanded_rows.append({\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'moments_id': row['id'],\n",
    "                'segment_id': segment_id,\n",
    "                'video_api_id': row['video_api_id']\n",
    "            })\n",
    "            current_id += 1\n",
    "    moments_segment = pd.DataFrame(expanded_rows)\n",
    "    # Create new DataFrame from expanded rows\n",
    "    try:\n",
    "    # Write DataFrame to PostgreSQL\n",
    "      moments_segment.to_sql(\n",
    "          'moments_segment',  # replace with your table name\n",
    "          engine,\n",
    "          if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "          index=False,\n",
    "          method='multi',\n",
    "          chunksize=1000  # adjust based on your data size\n",
    "      )\n",
    "      print(\"Data successfully written to database\")\n",
    "    except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "      engine.dispose()  # Clean up connection\n",
    "    return moments_segment\n",
    "  \n",
    "def mark_old_latest_moment(videoids, activities):\n",
    "   # Update query to set latest=FALSE\n",
    "   query = text(\"UPDATE public.moments SET latest = FALSE WHERE video_api_id IN :videoids AND activity IN :activities AND latest = TRUE\")\n",
    "   print(\"Executing Query on Database: \" + str(query))\n",
    "   \n",
    "   engine = create_engine(connection_string)\n",
    "   \n",
    "   # Run update query with parameters\n",
    "   with engine.connect() as connection:\n",
    "       result = connection.execute(query, {\n",
    "           \"videoids\": tuple(videoids), \n",
    "           \"activities\": tuple(activities)\n",
    "       })\n",
    "       # Commit the transaction\n",
    "       connection.commit()\n",
    "   \n",
    "   # Close connection\n",
    "   engine.dispose()\n",
    "   return result.rowcount  # Returns number of rows updated\n",
    "\n",
    "\n",
    "def mark_moment_as_irrelevant():\n",
    "   # Update query to set latest=FALSE\n",
    "   query = text(\"UPDATE moments SET relevant = FALSE WHERE (activity_type = 'Not Detected' OR target_person_type = 'Not Involved')\")\n",
    "   print(\"Executing Query on Database: \" + str(query))\n",
    "   \n",
    "   engine = create_engine(connection_string)\n",
    "   \n",
    "   # Run update query with parameters\n",
    "   with engine.connect() as connection:\n",
    "       result = connection.execute(query)\n",
    "       # Commit the transaction\n",
    "       connection.commit()\n",
    "   \n",
    "   # Close connection\n",
    "   engine.dispose()\n",
    "   return result.rowcount  # Returns number of rows updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_meeting_tags(video_id):\n",
    "    meta_data = get_video_object(video_id)\n",
    "    tags = meta_data.get('tags')[0]\n",
    "\n",
    "    query = text(\"UPDATE public.meetings SET speaker = :tags WHERE video_api_id = :video_id\")\n",
    "    engine = create_engine(connection_string)\n",
    "   \n",
    "   # Run update query with parameters\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query, {\n",
    "            \"video_id\": video_id, \n",
    "            \"tags\": tags\n",
    "            })\n",
    "        # Commit the transaction\n",
    "        connection.commit()\n",
    "    \n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    return result.rowcount  # Returns number of rows updated\n",
    "\n",
    "def get_meetings_with_missing_speaker():\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT video_api_id FROM public.meetings WHERE speaker IS NULL\")\n",
    "        result = connection.execute(query)\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    supabase_current_video_ids = list(df['video_api_id'])\n",
    "    return supabase_current_video_ids\n",
    "\n",
    "def get_meeting_baas_data(video_id):\n",
    "    try: \n",
    "        temp = get_video_object(video_id).get('metadata')[1].get('key')\n",
    "        data = get_video_object(video_id).get('metadata')[1].get('value') \n",
    "        is_meeting_baas = (temp == \"meeting_baas_raw_data\")\n",
    "        if is_meeting_baas:\n",
    "            is_meeting_baas = data\n",
    "        return is_meeting_baas\n",
    "    except IndexError:\n",
    "        is_meeting_baas = False\n",
    "        pprint(\"No Metadata or not Meeting Baas\")\n",
    "        return is_meeting_baas\n",
    "    except Exception as e:\n",
    "        is_meeting_baas = False\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return is_meeting_baas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vtt_transcript(meeting_data):\n",
    "    \"\"\"\n",
    "    Extracts transcript data from the meeting JSON data structure and formats it as VTT\n",
    "    with speaker tags.\n",
    "    \n",
    "    Args:\n",
    "        meeting_data (dict): The meeting data dictionary containing transcript information\n",
    "        \n",
    "    Returns:\n",
    "        str: A string containing the transcript in VTT format\n",
    "    \"\"\"\n",
    "    transcripts = meeting_data.get('transcripts', [])\n",
    "    vtt_content = \"WEBVTT\\n\\n\"  # VTT header\n",
    "    \n",
    "    segment_id = 0\n",
    "    for segment in transcripts:\n",
    "        # Only include segments that have words\n",
    "        if segment['words']:\n",
    "            # Format timestamps\n",
    "            start_time = format_timestamp(segment['start_time'])\n",
    "            end_time = format_timestamp(segment['end_time'])\n",
    "            timestamp = f\"{start_time} --> {end_time}\"\n",
    "            \n",
    "            # Format speaker and text\n",
    "            speaker = f\"<v {segment['speaker']}>\"\n",
    "            text = ' '.join(word['text'] for word in segment['words'])\n",
    "            \n",
    "            # Combine into VTT format\n",
    "            vtt_content += f\"{segment_id}\\n{timestamp}\\n{speaker} {text}\\n\\n\"\n",
    "            segment_id += 1\n",
    "    \n",
    "    return vtt_content\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    \"\"\"\n",
    "    Convert seconds to VTT timestamp format (HH:MM:SS.mmm)\n",
    "    \"\"\"\n",
    "    if seconds < 0:\n",
    "        return \"00:00.000\"\n",
    "    else:\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        seconds_remaining = seconds % 60\n",
    "        return f\"{hours:02d}:{minutes:02d}:{seconds_remaining:06.3f}\"\n",
    "\n",
    "def process_meeting_to_vtt(raw_data):\n",
    "    \"\"\"\n",
    "    Process the raw meeting data and convert to VTT format.\n",
    "    \n",
    "    Args:\n",
    "        raw_data (str): The raw meeting data string\n",
    "        \n",
    "    Returns:\n",
    "        str: VTT formatted transcript\n",
    "    \"\"\"\n",
    "    # Clean up the string and parse JSON\n",
    "    cleaned_data = raw_data.strip('()')\n",
    "    meeting_data = json.loads(cleaned_data)\n",
    "    \n",
    "    return extract_vtt_transcript(meeting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meeting_table_data(supabase_missing_video_ids):\n",
    "  \n",
    "  if len(supabase_missing_video_ids) > 0:\n",
    "    meetings = []\n",
    "    # Create a list of dictionaries with the required fields\n",
    "    for video_id in supabase_missing_video_ids:\n",
    "\n",
    "      meeting_baas_data = get_meeting_baas_data(video_id)\n",
    "\n",
    "      if(meeting_baas_data == False):\n",
    "        raw_data = get_video_object(video_id)\n",
    "        original_vtt_file = get_caption_text(video_id)\n",
    "        clean_vtt_file = build_clean_vtt_adjust(original_vtt_file, video_id)\n",
    "        summary = get_meeting_summary(clean_vtt_file, raw_data.get('tags')[0])\n",
    "        video_data = {\n",
    "        'video_api_id' : video_id,    \n",
    "        'name' : raw_data.get('title'),\n",
    "        'date' : raw_data.get('published_at'),\n",
    "        'speaker' : raw_data.get('tags')[0],\n",
    "        'original_vtt_file' : original_vtt_file,\n",
    "        'clean_vtt_file' : clean_vtt_file,\n",
    "        'summary' : summary\n",
    "        }\n",
    "        meetings.append(video_data)\n",
    "        break\n",
    "      \n",
    "      raw_data = get_video_object(video_id)\n",
    "      original_vtt_file = process_meeting_to_vtt(meeting_baas_data)\n",
    "      clean_vtt_file = build_clean_vtt_adjust(original_vtt_file, video_id)\n",
    "      summary = get_meeting_summary(clean_vtt_file, raw_data.get('tags')[0])\n",
    "      \n",
    "      video_data = {\n",
    "      'video_api_id' : video_id,    \n",
    "      'name' : raw_data.get('title'),\n",
    "      'date' : raw_data.get('published_at'),\n",
    "      'speaker' : raw_data.get('tags')[0],\n",
    "      'meeting_baas_original_json': meeting_baas_data,\n",
    "      'original_vtt_file' : original_vtt_file,\n",
    "      'clean_vtt_file' : clean_vtt_file,\n",
    "      'summary' : summary\n",
    "      }\n",
    "      meetings.append(video_data)\n",
    "    \n",
    "    meetings = pd.DataFrame(meetings)\n",
    "    return meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'No Metadata or not Meeting Baas'\n",
      "Data successfully written to database\n",
      "Processing video ID: vi3vHBTcK9aO4oZtY4uuNraW\n",
      "VTT VAD dataset successfully build for all videos\n",
      "Data successfully written to database\n"
     ]
    }
   ],
   "source": [
    "vad_lexicon = load_nrc_vad_lexicon(vad_lexicon_filepath)\n",
    "video_api_current_video_ids = get_video_idsv2()\n",
    "supabase_missing_video_ids = get_delta(video_api_current_video_ids)\n",
    "#pprint(supabase_missing_video_ids)\n",
    "supabase_missing_video_ids = ['vi3vHBTcK9aO4oZtY4uuNraW']\n",
    "meetings = generate_meeting_table_data(supabase_missing_video_ids)\n",
    "#pprint(meetings)\n",
    "write_meeting_table_data_to_supabase(meetings)\n",
    "#update_profile_meeting_table() -- Does not properly work while we do not have all users that currently have videos correctly onboarded\n",
    "segments = update_segments(supabase_missing_video_ids)\n",
    "write_segements_table_to_supabase(segments)\n",
    "\n",
    "# Other things for debugging\n",
    "#print(supabase_missing_video_ids)\n",
    "#supabase_missing_video_ids = ['vi5lUKF5SojsvO2eH5MdSXVs', 'vi4iA7ftEHA7F7kXxBz5TW1s', 'vi4Yb16priLky4Ze4x3ApG3C', 'vi7GkawMp69I47lCmepGg2Y1', 'vi17iPCCfSCPTTMMwSe8pF4v', 'vi5oPyx5KnBrR7JX4o3IKRxL', 'vi5tQVPfxGp8bEIsPrkYLc2t', 'vimgkWn5yc9eZpob5nXB4k5', 'vi82EUZk4sRGrV4MBYaYhyr', 'vi4Ro4yE0PR9xSZ7JKYTU2r6', 'vi4cHtqlN2qHZYWEcurYLXic', 'vi2r3uY6mjoU6gc6QjaMcZFk', 'vi2jqz22wk9sKKz8udDFa4Mv', 'vi3lhBdLr1b48zymbStBq65m', 'vi5RzuGHq6hVTXUZ6S2gc5FI', 'vi1RUWYlkj8srU7xJWhvIgf4', 'vi3veataLjXlJv4dEEvBGUIS', 'vi5dVoW7a6py6gDqonevdQhG', 'vi6izaRPNkne58IZ7zzjofeH', 'vi4fEA572F2t8znnmHtDUsPu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_detection(video_id):\n",
    "    prompt = emotion_prompt_builder()\n",
    "    caption_text = get_clean_vtt(video_id)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini-2024-07-18\",  # Corrected model name\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'{prompt}\\n\\n{caption_text}'\n",
    "            }\n",
    "        ],\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"Emotions\",\n",
    "                \"description\": \"Emotions\",\n",
    "                \"schema\": {\n",
    "                \n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"emotion_sequences\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"sequence_id\": {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"description\": \"A unique identifier for each sequence\"\n",
    "                                },\n",
    "                                \"segment_id_sequence_start\": {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"description\": \"The `segment_number` of the first segment within the identified sequence\"\n",
    "                                },\n",
    "                                \"segment_id_sequence_end\": {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"description\": \"The `segment_number` of the last segment within the identified sequence\"\n",
    "                                },\n",
    "                                \"speaker_name\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The name of the speaker it's all about\"\n",
    "                                },\n",
    "                                \"emotion\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The emotion that the speaker is demonstrating\"\n",
    "                                },\n",
    "                                \"emotion_intensity\": {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"description\": \"The intensity of the emotion that the speaker is demonstrating\",\n",
    "                                    \"minimum\": 0,\n",
    "                                    \"maximum\": 10\n",
    "                                },\n",
    "                                \"reasoning\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"A brief explanation summarizing the reasoning behind your selection\"\n",
    "                                },\n",
    "                                \"context\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"A brief explanation summarizing the context of the identified emotion\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"sequence_id\",\n",
    "                                \"segment_id_sequence_start\",\n",
    "                                \"segment_id_sequence_end\",\n",
    "                                \"speaker_name\",\n",
    "                                \"emotion\",\n",
    "                                \"emotion_intensity\",\n",
    "                                \"reasoning\",\n",
    "                                \"context\"\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"emotion_sequences\"\n",
    "                ]\n",
    "            }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {os.getenv(\"OPENAI_API_KEY\")}'\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        json=payload,\n",
    "        headers=headers\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "\n",
    "    chat_completion = response.json()\n",
    "\n",
    "    # Extract the content from the response\n",
    "    res = chat_completion['choices'][0]['message']['content']\n",
    "\n",
    "    json_data = json.loads(res)\n",
    "    df = pd.DataFrame(json_data['emotion_sequences'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>segment_id_sequence_start</th>\n",
       "      <th>segment_id_sequence_end</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_intensity</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>AJ Goldstein</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>5</td>\n",
       "      <td>AJ asks Darren about how he's handling the election results, indicating he is curious about Darren's perspective.</td>\n",
       "      <td>AJ attempts to engage Darren in a conversation about personal sentiments regarding current events.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>AJ Goldstein</td>\n",
       "      <td>Nostalgia</td>\n",
       "      <td>7</td>\n",
       "      <td>AJ expresses fond memories and appreciation when talking about his past experiences and relationships with Jeff.</td>\n",
       "      <td>AJ reminisces about his early connections and mentorship received from Jeff while discussing their shared experiences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>AJ Goldstein</td>\n",
       "      <td>Conviction</td>\n",
       "      <td>8</td>\n",
       "      <td>AJ strongly believes in the value of his business model and expresses confidence in their target market and success.</td>\n",
       "      <td>AJ discusses the importance of targeting STEM founders and expands on the empirical success they are experiencing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>Darren</td>\n",
       "      <td>Apprehension</td>\n",
       "      <td>6</td>\n",
       "      <td>Darren hesitates to engage fully due to obligations tied to his role as a fund manager, indicating a level of concern about stepping outside of those boundaries.</td>\n",
       "      <td>In response to AJ's request for broader collaboration, Darren expresses reluctance to extend beyond his existing fund's agreements.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>AJ Goldstein</td>\n",
       "      <td>Optimism</td>\n",
       "      <td>9</td>\n",
       "      <td>AJ showcases an optimistic outlook on the potential for collaboration and the successful future of his coaching business, reflecting high energy and hope.</td>\n",
       "      <td>AJ reaffirms his excitement about potential partnerships and the positive value he sees in his operations.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id  segment_id_sequence_start  segment_id_sequence_end  \\\n",
       "0            1                         14                       14   \n",
       "1            2                         20                       20   \n",
       "2            3                         40                       40   \n",
       "3            4                         59                       59   \n",
       "4            5                         58                       58   \n",
       "\n",
       "   speaker_name       emotion  emotion_intensity  \\\n",
       "0  AJ Goldstein     Curiosity                  5   \n",
       "1  AJ Goldstein     Nostalgia                  7   \n",
       "2  AJ Goldstein    Conviction                  8   \n",
       "3        Darren  Apprehension                  6   \n",
       "4  AJ Goldstein      Optimism                  9   \n",
       "\n",
       "                                                                                                                                                           reasoning  \\\n",
       "0                                                  AJ asks Darren about how he's handling the election results, indicating he is curious about Darren's perspective.   \n",
       "1                                                   AJ expresses fond memories and appreciation when talking about his past experiences and relationships with Jeff.   \n",
       "2                                               AJ strongly believes in the value of his business model and expresses confidence in their target market and success.   \n",
       "3  Darren hesitates to engage fully due to obligations tied to his role as a fund manager, indicating a level of concern about stepping outside of those boundaries.   \n",
       "4         AJ showcases an optimistic outlook on the potential for collaboration and the successful future of his coaching business, reflecting high energy and hope.   \n",
       "\n",
       "                                                                                                                               context  \n",
       "0                                   AJ attempts to engage Darren in a conversation about personal sentiments regarding current events.  \n",
       "1               AJ reminisces about his early connections and mentorship received from Jeff while discussing their shared experiences.  \n",
       "2                   AJ discusses the importance of targeting STEM founders and expands on the empirical success they are experiencing.  \n",
       "3  In response to AJ's request for broader collaboration, Darren expresses reluctance to extend beyond his existing fund's agreements.  \n",
       "4                           AJ reaffirms his excitement about potential partnerships and the positive value he sees in his operations.  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = emotion_detection(\"vi1RUWYlkj8srU7xJWhvIgf4\")\n",
    "temp.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = \"vi1RUWYlkj8srU7xJWhvIgf4\"\n",
    "temp2 = process_activity_detection(temp)\n",
    "  moments_emotions = temp\n",
    "  column_mapping = {\n",
    "      'context': 'summary',\n",
    "      'emotion': 'activity_type',\n",
    "      'reasoning': 'activity_reasoning',\n",
    "       \t\n",
    "  }\n",
    "  \n",
    "  moments_renamed = moments_emotions.rename(columns=column_mapping)\n",
    "  \n",
    "  # Create enhancement_id (two approaches you can try):\n",
    "  # Approach 1 - direct UUID objects\n",
    "  moments_renamed['video_api_id'] = video_id\n",
    "  moments_renamed['id'] = [str(uuid.uuid4()) for _ in range(len(moments_renamed))]\n",
    "  moments_renamed['latest'] = 'TRUE'\n",
    "  ##moments_columns = ['id','segment_id_sequence_start', 'segment_id_sequence_end', 'summary', 'title', 'segment_start_timestamp', 'segment_end_timestamp', 'segment_start_timestamp_in_seconds', 'segment_end_timestamp_in_seconds', 'video_api_id', 'activity_type', 'activity_reasoning', 'target_person_type', 'target_person_reasoning', 'activity', 'moment_url', 'latest']\n",
    "  ##moments_renamed = moments_renamed[moments_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Columns in Moments\n",
    "\n",
    "id --> Good (UUID)\n",
    "segment_id_sequence_start --> Good\n",
    "segment_id_sequence_end --> Good\n",
    "summary --> Context\n",
    "title --> Emotion?\n",
    "segment_start_timestamp --> Good\n",
    "segment_end_timestamp  --> Good\n",
    "segment_start_timestamp_in_seconds --> Good\n",
    "segment_end_timestamp_in_seconds --> Good\n",
    "video_api_id --> Good\n",
    "activity_type --> The of emotion\n",
    "activity_reasoning --> reasoning\n",
    "target_person_type --> speaker\n",
    "target_person_reasoning --> Null\n",
    "activity --> Emotion\n",
    "score --> intensity\n",
    "latest --> DEFAULT TRUE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi6TBTdOQ3bkW2b7ku6xtvbK, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6TBTdOQ3bkW2b7ku6xtvbK, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6TBTdOQ3bkW2b7ku6xtvbK, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6TBTdOQ3bkW2b7ku6xtvbK, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6TBTdOQ3bkW2b7ku6xtvbK, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi3MC0JsaO4n4cA7cYgYzpb4, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi3MC0JsaO4n4cA7cYgYzpb4, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi3MC0JsaO4n4cA7cYgYzpb4, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi3MC0JsaO4n4cA7cYgYzpb4, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi3MC0JsaO4n4cA7cYgYzpb4, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi4jzbO8E3eWXzvCGz7XNI0w, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4jzbO8E3eWXzvCGz7XNI0w, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4jzbO8E3eWXzvCGz7XNI0w, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4jzbO8E3eWXzvCGz7XNI0w, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4jzbO8E3eWXzvCGz7XNI0w, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi4flB6clm0iow6IFTbC7emI, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4flB6clm0iow6IFTbC7emI, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4flB6clm0iow6IFTbC7emI, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4flB6clm0iow6IFTbC7emI, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi4flB6clm0iow6IFTbC7emI, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi7YPIONLTIkuIc1odaRFv5, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7YPIONLTIkuIc1odaRFv5, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7YPIONLTIkuIc1odaRFv5, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7YPIONLTIkuIc1odaRFv5, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7YPIONLTIkuIc1odaRFv5, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi18qSrl7wIdeYOKuDg7YQBx, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi18qSrl7wIdeYOKuDg7YQBx, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi18qSrl7wIdeYOKuDg7YQBx, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi18qSrl7wIdeYOKuDg7YQBx, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi18qSrl7wIdeYOKuDg7YQBx, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi6aqbh5ikJLOYkqOdO7TvN1, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6aqbh5ikJLOYkqOdO7TvN1, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6aqbh5ikJLOYkqOdO7TvN1, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6aqbh5ikJLOYkqOdO7TvN1, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi6aqbh5ikJLOYkqOdO7TvN1, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi7ITVcbI2cXqYj2CnwKvSXg, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7ITVcbI2cXqYj2CnwKvSXg, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7ITVcbI2cXqYj2CnwKvSXg, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7ITVcbI2cXqYj2CnwKvSXg, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi7ITVcbI2cXqYj2CnwKvSXg, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi5lUKF5SojsvO2eH5MdSXVs, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi5lUKF5SojsvO2eH5MdSXVs, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi5lUKF5SojsvO2eH5MdSXVs, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi5lUKF5SojsvO2eH5MdSXVs, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi5lUKF5SojsvO2eH5MdSXVs, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi31gHvd0MMz8FonUstjUyMe, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi31gHvd0MMz8FonUstjUyMe, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi31gHvd0MMz8FonUstjUyMe, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi31gHvd0MMz8FonUstjUyMe, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi31gHvd0MMz8FonUstjUyMe, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop\n",
      "Processing video ID: vi1GPAuvhakg74TUpNoMMUvc, for Goal Setting targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi1GPAuvhakg74TUpNoMMUvc, for Team Conflict targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi1GPAuvhakg74TUpNoMMUvc, for Feedback targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi1GPAuvhakg74TUpNoMMUvc, for Delegation targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video ID: vi1GPAuvhakg74TUpNoMMUvc, for Decision Making targeted towards Kanishka Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HYDOTRA\\AppData\\Local\\Temp\\ipykernel_19764\\425868447.py:26: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  activity_data = pd.read_json(activity_detection_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video selection has been process for moments activities selection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>segment_id_sequence_start</th>\n",
       "      <th>segment_id_sequence_end</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>segment_start_timestamp</th>\n",
       "      <th>segment_end_timestamp</th>\n",
       "      <th>segment_start_timestamp_in_seconds</th>\n",
       "      <th>segment_end_timestamp_in_seconds</th>\n",
       "      <th>video_id</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>activity_reasoning</th>\n",
       "      <th>target_person_type</th>\n",
       "      <th>target_person_reasoning</th>\n",
       "      <th>activity</th>\n",
       "      <th>Moment_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>54</td>\n",
       "      <td>Bill and Kanishka discuss the need for a consistent metrics solution that aligns with both their father's needs and broader organizational goals. They emphasize the importance of defining metrics and establishing a common analytics database to track performance effectively.</td>\n",
       "      <td>Defining Metrics and Analytics</td>\n",
       "      <td>20:26.903</td>\n",
       "      <td>26:54.400</td>\n",
       "      <td>1226</td>\n",
       "      <td>1614</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "      <td>Tactical Goals</td>\n",
       "      <td>Kanishka Rao emphasized the importance of defining time frames and baseline data for measuring impacts, indicating a structured approach to achieving specific metrics related to exacerbations and hospitalizations.</td>\n",
       "      <td>Participating</td>\n",
       "      <td>Kanishka Rao actively engaged in goal setting by discussing the importance of time frames, defining metrics, and emphasizing the significance of baseline data for measuring impacts.</td>\n",
       "      <td>Goal Setting</td>\n",
       "      <td>https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>Kanishka expresses the need for clarity on the population to be used for metrics calculations. Bill agrees to take the lead on proposing a population definition for their metrics, ensuring stakeholder input and agreement.</td>\n",
       "      <td>Population Definition for Metrics</td>\n",
       "      <td>31:14.914</td>\n",
       "      <td>32:15.470</td>\n",
       "      <td>1874</td>\n",
       "      <td>1935</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "      <td>Tactical Goals</td>\n",
       "      <td>Kanishka Rao is emphasizing the need for someone to take responsibility for determining the population to be used, which indicates a focused initiative that aligns with achieving a broader strategic aim.</td>\n",
       "      <td>Participating</td>\n",
       "      <td>Kanishka Rao is actively engaged in goal setting by suggesting that someone needs to take responsibility for determining the population to be used, indicating involvement in the decision-making process.</td>\n",
       "      <td>Goal Setting</td>\n",
       "      <td>https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>Kanishka and Bill discuss the importance of using a common definition for pilot and control populations across different teams. They agree on the need for alignment in metrics definitions to ensure consistency in their evaluations.</td>\n",
       "      <td>Aligning Metrics Definitions</td>\n",
       "      <td>35:02.570</td>\n",
       "      <td>37:31.346</td>\n",
       "      <td>2102</td>\n",
       "      <td>2251</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "      <td>Tactical Goals</td>\n",
       "      <td>Kanishka Rao emphasized the importance of using a common definition for pilot and control populations across different activities, indicating a collaborative approach to establishing specific goals that align with the overall objectives of the team.</td>\n",
       "      <td>Participating</td>\n",
       "      <td>Kanishka Rao actively engaged in goal setting by discussing the importance of using a common definition for pilot and control population, indicating a collaborative approach to establishing goals across different activities.</td>\n",
       "      <td>Goal Setting</td>\n",
       "      <td>https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>Kanishka outlines the different levels of tasks he is managing, including executive responsibilities and individual contributions. Bill emphasizes the need for transparency and accountability in these roles to ensure effective management.</td>\n",
       "      <td>Managing Executive Responsibilities</td>\n",
       "      <td>47:26.229</td>\n",
       "      <td>49:13.090</td>\n",
       "      <td>2846</td>\n",
       "      <td>2953</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "      <td>Not Detected</td>\n",
       "      <td>The discussion revolves around the potential impact of an intern and transparency issues, but does not involve any specific goal setting or planning activities.</td>\n",
       "      <td>Not Participating</td>\n",
       "      <td>Kanishka Rao is discussing the potential impact of an intern but is not actively contributing to defining or planning specific goals.</td>\n",
       "      <td>Goal Setting</td>\n",
       "      <td>https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>181</td>\n",
       "      <td>186</td>\n",
       "      <td>Kanishka identifies the need for a chief of staff to help manage his workload and responsibilities. Bill supports this idea, suggesting that hiring someone could help alleviate pressure and allow for better focus on executive tasks.</td>\n",
       "      <td>Need for Chief of Staff</td>\n",
       "      <td>01:16:05.344</td>\n",
       "      <td>01:18:55.814</td>\n",
       "      <td>4565</td>\n",
       "      <td>4735</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "      <td>Not Detected</td>\n",
       "      <td>The conversation primarily revolves around Kanishka Rao's current responsibilities and challenges, as well as discussions about staffing and support, without any specific goal setting or defining of objectives.</td>\n",
       "      <td>Not Participating</td>\n",
       "      <td>Kanishka Rao is discussing his current responsibilities and challenges but is not actively contributing to the goal setting process or defining specific goals.</td>\n",
       "      <td>Goal Setting</td>\n",
       "      <td>https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=4565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Kanishka outlines the priorities for the month, emphasizing the need to focus on selling to health systems and preparing for upcoming conferences, which initiates a discussion on resource allocation and urgency.</td>\n",
       "      <td>Monthly Priorities Discussion</td>\n",
       "      <td>01:00.750</td>\n",
       "      <td>05:47.845</td>\n",
       "      <td>60</td>\n",
       "      <td>347</td>\n",
       "      <td>vi1GPAuvhakg74TUpNoMMUvc</td>\n",
       "      <td>Strategic Decision</td>\n",
       "      <td>Kanishka Rao is outlining the priorities for the month, emphasizing the need to focus on selling to health systems and developing strategies for the SUa offering, which aligns with overarching organizational goals.</td>\n",
       "      <td>Participating</td>\n",
       "      <td>Kanishka Rao is actively discussing priorities, outlining strategies, and soliciting feedback from others, indicating engagement in the decision-making process.</td>\n",
       "      <td>Decision Making</td>\n",
       "      <td>https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Sriram questions the prioritization of GDMT improvement over SBIR, highlighting the time-sensitive nature of the tasks and prompting a reevaluation of priorities.</td>\n",
       "      <td>Prioritization of Tasks</td>\n",
       "      <td>05:47.949</td>\n",
       "      <td>07:24.213</td>\n",
       "      <td>347</td>\n",
       "      <td>444</td>\n",
       "      <td>vi1GPAuvhakg74TUpNoMMUvc</td>\n",
       "      <td>Tactical Decision</td>\n",
       "      <td>Sriram Krishnan is questioning the prioritization of tasks based on their deadlines and impact, specifically weighing the importance of GDMT improvement against SBIR, which indicates a decision-making process about resource allocation and task prioritization within the team's objectives.</td>\n",
       "      <td>Not Participating</td>\n",
       "      <td>Kanishka Rao did not contribute to the discussion or decision-making process during this interaction.</td>\n",
       "      <td>Decision Making</td>\n",
       "      <td>https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>Bill expresses concerns about the urgency of GDMT improvement versus securing the AZ contract, leading to a consensus on prioritizing immediate tasks to meet deadlines.</td>\n",
       "      <td>Urgency of Contractual Obligations</td>\n",
       "      <td>20:04.073</td>\n",
       "      <td>21:53.173</td>\n",
       "      <td>1204</td>\n",
       "      <td>1313</td>\n",
       "      <td>vi1GPAuvhakg74TUpNoMMUvc</td>\n",
       "      <td>Strategic Decision</td>\n",
       "      <td>Bill Landi is discussing the prioritization of obtaining the AZ contract and the associated risks, indicating a high-level decision that impacts the organization's strategic direction and resource allocation.</td>\n",
       "      <td>Not Participating</td>\n",
       "      <td>Kanishka Rao is not mentioned in the discussion and does not contribute to the decision-making process.</td>\n",
       "      <td>Decision Making</td>\n",
       "      <td>https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>Kanishka emphasizes the importance of securing budget allocation from AZ, which is critical for future contracts, leading to a discussion on the implications of prioritizing this task.</td>\n",
       "      <td>Budget Allocation Importance</td>\n",
       "      <td>24:19.113</td>\n",
       "      <td>24:41.183</td>\n",
       "      <td>1459</td>\n",
       "      <td>1481</td>\n",
       "      <td>vi1GPAuvhakg74TUpNoMMUvc</td>\n",
       "      <td>Strategic Decision</td>\n",
       "      <td>Kanishka Rao is highlighting the importance of securing the budget to enable signing a large contract, which indicates a focus on long-term goals and resource allocation for future fundraising efforts.</td>\n",
       "      <td>Participating</td>\n",
       "      <td>Kanishka Rao is discussing the implications of the budget on future contracts and fundraising, actively contributing to the decision-making process.</td>\n",
       "      <td>Decision Making</td>\n",
       "      <td>https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=1459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>The team agrees on the need to focus on the top three priorities for the month, recognizing that the outcomes will significantly impact future business decisions.</td>\n",
       "      <td>Focus on Top Priorities</td>\n",
       "      <td>29:31.030</td>\n",
       "      <td>29:53.256</td>\n",
       "      <td>1771</td>\n",
       "      <td>1793</td>\n",
       "      <td>vi1GPAuvhakg74TUpNoMMUvc</td>\n",
       "      <td>Strategic Decision</td>\n",
       "      <td>Scott Weissman is discussing the need to focus on three key initiatives in September that will influence business outcomes and priorities moving forward, indicating a high-level decision that aligns with overarching organizational goals.</td>\n",
       "      <td>Not Participating</td>\n",
       "      <td>Kanishka Rao is not mentioned or involved in the discussion or decision-making process during this interaction.</td>\n",
       "      <td>Decision Making</td>\n",
       "      <td>https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=1771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence_id  segment_id_sequence_start  segment_id_sequence_end  \\\n",
       "0              1                         38                       54   \n",
       "1              2                         65                       68   \n",
       "2              3                         78                       84   \n",
       "3              4                        112                      118   \n",
       "4              5                        181                      186   \n",
       "..           ...                        ...                      ...   \n",
       "236            1                         11                       11   \n",
       "237            2                         12                       12   \n",
       "238            3                         36                       36   \n",
       "239            4                         44                       44   \n",
       "240            5                         60                       60   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                summary  \\\n",
       "0    Bill and Kanishka discuss the need for a consistent metrics solution that aligns with both their father's needs and broader organizational goals. They emphasize the importance of defining metrics and establishing a common analytics database to track performance effectively.   \n",
       "1                                                         Kanishka expresses the need for clarity on the population to be used for metrics calculations. Bill agrees to take the lead on proposing a population definition for their metrics, ensuring stakeholder input and agreement.   \n",
       "2                                               Kanishka and Bill discuss the importance of using a common definition for pilot and control populations across different teams. They agree on the need for alignment in metrics definitions to ensure consistency in their evaluations.   \n",
       "3                                        Kanishka outlines the different levels of tasks he is managing, including executive responsibilities and individual contributions. Bill emphasizes the need for transparency and accountability in these roles to ensure effective management.   \n",
       "4                                              Kanishka identifies the need for a chief of staff to help manage his workload and responsibilities. Bill supports this idea, suggesting that hiring someone could help alleviate pressure and allow for better focus on executive tasks.   \n",
       "..                                                                                                                                                                                                                                                                                  ...   \n",
       "236                                                                 Kanishka outlines the priorities for the month, emphasizing the need to focus on selling to health systems and preparing for upcoming conferences, which initiates a discussion on resource allocation and urgency.   \n",
       "237                                                                                                                  Sriram questions the prioritization of GDMT improvement over SBIR, highlighting the time-sensitive nature of the tasks and prompting a reevaluation of priorities.   \n",
       "238                                                                                                            Bill expresses concerns about the urgency of GDMT improvement versus securing the AZ contract, leading to a consensus on prioritizing immediate tasks to meet deadlines.   \n",
       "239                                                                                            Kanishka emphasizes the importance of securing budget allocation from AZ, which is critical for future contracts, leading to a discussion on the implications of prioritizing this task.   \n",
       "240                                                                                                                  The team agrees on the need to focus on the top three priorities for the month, recognizing that the outcomes will significantly impact future business decisions.   \n",
       "\n",
       "                                   title segment_start_timestamp  \\\n",
       "0         Defining Metrics and Analytics               20:26.903   \n",
       "1      Population Definition for Metrics               31:14.914   \n",
       "2           Aligning Metrics Definitions               35:02.570   \n",
       "3    Managing Executive Responsibilities               47:26.229   \n",
       "4                Need for Chief of Staff            01:16:05.344   \n",
       "..                                   ...                     ...   \n",
       "236        Monthly Priorities Discussion               01:00.750   \n",
       "237              Prioritization of Tasks               05:47.949   \n",
       "238   Urgency of Contractual Obligations               20:04.073   \n",
       "239         Budget Allocation Importance               24:19.113   \n",
       "240              Focus on Top Priorities               29:31.030   \n",
       "\n",
       "    segment_end_timestamp  segment_start_timestamp_in_seconds  \\\n",
       "0               26:54.400                                1226   \n",
       "1               32:15.470                                1874   \n",
       "2               37:31.346                                2102   \n",
       "3               49:13.090                                2846   \n",
       "4            01:18:55.814                                4565   \n",
       "..                    ...                                 ...   \n",
       "236             05:47.845                                  60   \n",
       "237             07:24.213                                 347   \n",
       "238             21:53.173                                1204   \n",
       "239             24:41.183                                1459   \n",
       "240             29:53.256                                1771   \n",
       "\n",
       "     segment_end_timestamp_in_seconds                  video_id  \\\n",
       "0                                1614  vi6TBTdOQ3bkW2b7ku6xtvbK   \n",
       "1                                1935  vi6TBTdOQ3bkW2b7ku6xtvbK   \n",
       "2                                2251  vi6TBTdOQ3bkW2b7ku6xtvbK   \n",
       "3                                2953  vi6TBTdOQ3bkW2b7ku6xtvbK   \n",
       "4                                4735  vi6TBTdOQ3bkW2b7ku6xtvbK   \n",
       "..                                ...                       ...   \n",
       "236                               347  vi1GPAuvhakg74TUpNoMMUvc   \n",
       "237                               444  vi1GPAuvhakg74TUpNoMMUvc   \n",
       "238                              1313  vi1GPAuvhakg74TUpNoMMUvc   \n",
       "239                              1481  vi1GPAuvhakg74TUpNoMMUvc   \n",
       "240                              1793  vi1GPAuvhakg74TUpNoMMUvc   \n",
       "\n",
       "          activity_type  \\\n",
       "0        Tactical Goals   \n",
       "1        Tactical Goals   \n",
       "2        Tactical Goals   \n",
       "3          Not Detected   \n",
       "4          Not Detected   \n",
       "..                  ...   \n",
       "236  Strategic Decision   \n",
       "237   Tactical Decision   \n",
       "238  Strategic Decision   \n",
       "239  Strategic Decision   \n",
       "240  Strategic Decision   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                   activity_reasoning  \\\n",
       "0                                                                               Kanishka Rao emphasized the importance of defining time frames and baseline data for measuring impacts, indicating a structured approach to achieving specific metrics related to exacerbations and hospitalizations.   \n",
       "1                                                                                         Kanishka Rao is emphasizing the need for someone to take responsibility for determining the population to be used, which indicates a focused initiative that aligns with achieving a broader strategic aim.   \n",
       "2                                           Kanishka Rao emphasized the importance of using a common definition for pilot and control populations across different activities, indicating a collaborative approach to establishing specific goals that align with the overall objectives of the team.   \n",
       "3                                                                                                                                    The discussion revolves around the potential impact of an intern and transparency issues, but does not involve any specific goal setting or planning activities.   \n",
       "4                                                                                  The conversation primarily revolves around Kanishka Rao's current responsibilities and challenges, as well as discussions about staffing and support, without any specific goal setting or defining of objectives.   \n",
       "..                                                                                                                                                                                                                                                                                                ...   \n",
       "236                                                                            Kanishka Rao is outlining the priorities for the month, emphasizing the need to focus on selling to health systems and developing strategies for the SUa offering, which aligns with overarching organizational goals.   \n",
       "237  Sriram Krishnan is questioning the prioritization of tasks based on their deadlines and impact, specifically weighing the importance of GDMT improvement against SBIR, which indicates a decision-making process about resource allocation and task prioritization within the team's objectives.   \n",
       "238                                                                                  Bill Landi is discussing the prioritization of obtaining the AZ contract and the associated risks, indicating a high-level decision that impacts the organization's strategic direction and resource allocation.   \n",
       "239                                                                                         Kanishka Rao is highlighting the importance of securing the budget to enable signing a large contract, which indicates a focus on long-term goals and resource allocation for future fundraising efforts.   \n",
       "240                                                     Scott Weissman is discussing the need to focus on three key initiatives in September that will influence business outcomes and priorities moving forward, indicating a high-level decision that aligns with overarching organizational goals.   \n",
       "\n",
       "    target_person_type  \\\n",
       "0        Participating   \n",
       "1        Participating   \n",
       "2        Participating   \n",
       "3    Not Participating   \n",
       "4    Not Participating   \n",
       "..                 ...   \n",
       "236      Participating   \n",
       "237  Not Participating   \n",
       "238  Not Participating   \n",
       "239      Participating   \n",
       "240  Not Participating   \n",
       "\n",
       "                                                                                                                                                                                                              target_person_reasoning  \\\n",
       "0                                               Kanishka Rao actively engaged in goal setting by discussing the importance of time frames, defining metrics, and emphasizing the significance of baseline data for measuring impacts.   \n",
       "1                          Kanishka Rao is actively engaged in goal setting by suggesting that someone needs to take responsibility for determining the population to be used, indicating involvement in the decision-making process.   \n",
       "2    Kanishka Rao actively engaged in goal setting by discussing the importance of using a common definition for pilot and control population, indicating a collaborative approach to establishing goals across different activities.   \n",
       "3                                                                                               Kanishka Rao is discussing the potential impact of an intern but is not actively contributing to defining or planning specific goals.   \n",
       "4                                                                     Kanishka Rao is discussing his current responsibilities and challenges but is not actively contributing to the goal setting process or defining specific goals.   \n",
       "..                                                                                                                                                                                                                                ...   \n",
       "236                                                                  Kanishka Rao is actively discussing priorities, outlining strategies, and soliciting feedback from others, indicating engagement in the decision-making process.   \n",
       "237                                                                                                                             Kanishka Rao did not contribute to the discussion or decision-making process during this interaction.   \n",
       "238                                                                                                                           Kanishka Rao is not mentioned in the discussion and does not contribute to the decision-making process.   \n",
       "239                                                                              Kanishka Rao is discussing the implications of the budget on future contracts and fundraising, actively contributing to the decision-making process.   \n",
       "240                                                                                                                   Kanishka Rao is not mentioned or involved in the discussion or decision-making process during this interaction.   \n",
       "\n",
       "            activity  \\\n",
       "0       Goal Setting   \n",
       "1       Goal Setting   \n",
       "2       Goal Setting   \n",
       "3       Goal Setting   \n",
       "4       Goal Setting   \n",
       "..               ...   \n",
       "236  Decision Making   \n",
       "237  Decision Making   \n",
       "238  Decision Making   \n",
       "239  Decision Making   \n",
       "240  Decision Making   \n",
       "\n",
       "                                                       Moment_url  \n",
       "0    https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=1226  \n",
       "1    https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=1874  \n",
       "2    https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=2102  \n",
       "3    https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=2846  \n",
       "4    https://embed.api.video/vod/vi6TBTdOQ3bkW2b7ku6xtvbK#;t=4565  \n",
       "..                                                            ...  \n",
       "236    https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=60  \n",
       "237   https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=347  \n",
       "238  https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=1204  \n",
       "239  https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=1459  \n",
       "240  https://embed.api.video/vod/vi1GPAuvhakg74TUpNoMMUvc#;t=1771  \n",
       "\n",
       "[241 rows x 16 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_type_selector = [\"Feedback\",\n",
    "                         \"Decision Making\",\n",
    "                         \"Delegation\",\n",
    "                         \"Team Conflict\",\n",
    "                         \"Goal Setting\"\n",
    "  #\"Test\"\n",
    "                         ]\n",
    "\n",
    "## Apply to meeting that have been recently added\n",
    "#ideo_selector = filtered_data\n",
    "video_selector = [{\"videoId\":\"vi6TBTdOQ3bkW2b7ku6xtvbK\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi3MC0JsaO4n4cA7cYgYzpb4\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi4jzbO8E3eWXzvCGz7XNI0w\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi4flB6clm0iow6IFTbC7emI\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi7YPIONLTIkuIc1odaRFv5\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi18qSrl7wIdeYOKuDg7YQBx\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi6aqbh5ikJLOYkqOdO7TvN1\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi7ITVcbI2cXqYj2CnwKvSXg\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi5lUKF5SojsvO2eH5MdSXVs\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi31gHvd0MMz8FonUstjUyMe\", \"tags\":[\"Kanishka Rao\"]},\n",
    "{\"videoId\":\"vi1GPAuvhakg74TUpNoMMUvc\", \"tags\":[\"Kanishka Rao\"]}]\n",
    "\n",
    "api_video = ApiVideoAuth(os.getenv(\"API_VIDEO_API_KEY\"))\n",
    "api_video.authenticate()\n",
    "\n",
    "openai = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for video in video_selector:\n",
    "    print(\"Starting Loop\")\n",
    "    target_person = video['tags'][0]\n",
    "    video_id = video['videoId']\n",
    "    video = api_video.get_video(video_id)\n",
    "    caption_text = build_clean_vtt(video_id)\n",
    "\n",
    "    if \"Goal Setting\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Goal Setting targeted towards {target_person}\")\n",
    "\n",
    "        goal_setting_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Team Conflict\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Team Conflict targeted towards {target_person}\")\n",
    "\n",
    "        team_conflict_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Feedback\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Feedback targeted towards {target_person}\")\n",
    "\n",
    "        feedback_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Delegation\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Delegation targeted towards {target_person}\")\n",
    "\n",
    "        delegation_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Decision Making\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Decision Making targeted towards {target_person}\")\n",
    "\n",
    "        decision_making_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "print(\"Video selection has been process for moments activities selection\")\n",
    "final_df.head(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Query on Database: UPDATE public.moments SET latest = FALSE WHERE video_api_id IN :videoids AND activity IN :activities AND latest = TRUE\n",
      "Found 129 old moments and set them to latest = False\n",
      "Data successfully written to database\n",
      "241 moments data has been added to the database\n",
      "Moments data has been added to the database\n",
      "Data successfully written to database\n",
      "Moments Segement data has been added to the database\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>moments_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>video_api_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3b4a1cd0-a796-461e-8b0b-9b40aec20d8e</td>\n",
       "      <td>cf53d0ea-0ac7-4f90-93fa-657983742243</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK38</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9c326cca-4550-4266-8c9b-09fb47ad5231</td>\n",
       "      <td>cf53d0ea-0ac7-4f90-93fa-657983742243</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK39</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b888ad6e-5a17-467f-9ef6-063a36e888b1</td>\n",
       "      <td>cf53d0ea-0ac7-4f90-93fa-657983742243</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK40</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e4a62708-4c16-4777-9f94-7b6f46aaf8b2</td>\n",
       "      <td>cf53d0ea-0ac7-4f90-93fa-657983742243</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK41</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eefa81a2-5c02-46e8-b6ad-ec0b5c0b7520</td>\n",
       "      <td>cf53d0ea-0ac7-4f90-93fa-657983742243</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK42</td>\n",
       "      <td>vi6TBTdOQ3bkW2b7ku6xtvbK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                            moments_id  \\\n",
       "0  3b4a1cd0-a796-461e-8b0b-9b40aec20d8e  cf53d0ea-0ac7-4f90-93fa-657983742243   \n",
       "1  9c326cca-4550-4266-8c9b-09fb47ad5231  cf53d0ea-0ac7-4f90-93fa-657983742243   \n",
       "2  b888ad6e-5a17-467f-9ef6-063a36e888b1  cf53d0ea-0ac7-4f90-93fa-657983742243   \n",
       "3  e4a62708-4c16-4777-9f94-7b6f46aaf8b2  cf53d0ea-0ac7-4f90-93fa-657983742243   \n",
       "4  eefa81a2-5c02-46e8-b6ad-ec0b5c0b7520  cf53d0ea-0ac7-4f90-93fa-657983742243   \n",
       "\n",
       "                   segment_id              video_api_id  \n",
       "0  vi6TBTdOQ3bkW2b7ku6xtvbK38  vi6TBTdOQ3bkW2b7ku6xtvbK  \n",
       "1  vi6TBTdOQ3bkW2b7ku6xtvbK39  vi6TBTdOQ3bkW2b7ku6xtvbK  \n",
       "2  vi6TBTdOQ3bkW2b7ku6xtvbK40  vi6TBTdOQ3bkW2b7ku6xtvbK  \n",
       "3  vi6TBTdOQ3bkW2b7ku6xtvbK41  vi6TBTdOQ3bkW2b7ku6xtvbK  \n",
       "4  vi6TBTdOQ3bkW2b7ku6xtvbK42  vi6TBTdOQ3bkW2b7ku6xtvbK  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "video_selector_only_ids = [item['videoId'] for item in video_selector] \n",
    "\n",
    "rows_updated = mark_old_latest_moment(video_selector_only_ids, activity_type_selector)\n",
    "print(f\"Found {rows_updated} old moments and set them to latest = False\")\n",
    "final_df = add_new_moments(final_df)\n",
    "test  = (len(final_df))\n",
    "print(f\"{test} moments data has been added to the database\")\n",
    "print(\"Moments data has been added to the database\")\n",
    "debug = expand_moments_to_segments(final_df)\n",
    "print(\"Moments Segement data has been added to the database\")\n",
    "debug.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
