{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import uuid\n",
    "import apivideo\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "from openai import OpenAI\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "from apivideo.api import videos_api\n",
    "from apivideo.model.too_many_requests import TooManyRequests\n",
    "from apivideo.model.videos_list_response import VideosListResponse\n",
    "from apivideo.model.bad_request import BadRequest\n",
    "\n",
    "load_dotenv()\n",
    "vad_lexicon_filepath = 'NRC_VAD_Lexicon.csv'\n",
    "\n",
    "# Database connection parameters\n",
    "db_user = \"postgres.gukeqqpzhaignmhdduma\"  # usually this for Supabase\n",
    "db_password = os.getenv(\"SUPABASE_PW\")\n",
    "db_host = \"aws-0-us-east-1.pooler.supabase.com\"  # from your Supabase connection settings\n",
    "db_name = \"postgres\"  # usually this for Supabase\n",
    "# Create connection string - note the quoted password to handle special characters\n",
    "connection_string = f\"postgresql://{db_user}:{quote_plus(db_password)}@{db_host}:5432/{db_name}\"\n",
    "\n",
    "openai = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiVideoAuth:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.access_token = None\n",
    "        self.refresh_token = None\n",
    "        self.token_expiration = None\n",
    "        self.base_url = \"https://ws.api.video\"\n",
    "        self.csv_file = \"video_tags.csv\"\n",
    "        self.existing_tags = self._load_existing_tags()\n",
    "\n",
    "    def authenticate(self):\n",
    "        url = f\"{self.base_url}/auth/api-key\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        data = {\"apiKey\": self.api_key}\n",
    "\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            token_data = response.json()\n",
    "            self.access_token = token_data[\"access_token\"]\n",
    "            self.refresh_token = token_data[\"refresh_token\"]\n",
    "            self.token_expiration = time.time() + token_data[\"expires_in\"]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Failed to authenticate: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    def refresh_access_token(self):\n",
    "        url = f\"{self.base_url}/auth/refresh\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        }\n",
    "        data = {\"refreshToken\": self.refresh_token}\n",
    "\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            token_data = response.json()\n",
    "            self.access_token = token_data[\"access_token\"]\n",
    "            self.refresh_token = token_data[\"refresh_token\"]\n",
    "            self.token_expiration = time.time() + token_data[\"expires_in\"]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Failed to refresh token: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    def get_access_token(self):\n",
    "        if not self.access_token or time.time() >= self.token_expiration:\n",
    "            print(\"Token expired or not available, refreshing...\")\n",
    "            self.refresh_access_token()\n",
    "        return self.access_token\n",
    "\n",
    "    def _load_existing_tags(self):\n",
    "        existing_tags = {}\n",
    "        if os.path.isfile(self.csv_file):\n",
    "            with open(self.csv_file, \"r\", newline=\"\") as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                next(reader)  # Skip header\n",
    "                for row in reader:\n",
    "                    video_id, tag = row\n",
    "                    if video_id not in existing_tags:\n",
    "                        existing_tags[video_id] = set()\n",
    "                    existing_tags[video_id].add(tag)\n",
    "        return existing_tags\n",
    "\n",
    "    def _save_tags_to_csv(self, video_id, tags):\n",
    "        new_tags = False\n",
    "        if video_id not in self.existing_tags:\n",
    "            self.existing_tags[video_id] = set()\n",
    "\n",
    "        for tag in tags:\n",
    "            if tag not in self.existing_tags[video_id]:\n",
    "                self.existing_tags[video_id].add(tag)\n",
    "                new_tags = True\n",
    "                with open(self.csv_file, \"a\", newline=\"\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([video_id, tag])\n",
    "\n",
    "\n",
    "    def _make_request(self, method, endpoint, data=None, params=None, files=None):\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        headers = {\"Authorization\": f\"Bearer {self.get_access_token()}\"}\n",
    "\n",
    "        if data and not files:\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "            response = requests.request(\n",
    "                method, url, json=data, params=params, headers=headers\n",
    "            )\n",
    "        else:\n",
    "            response = requests.request(\n",
    "                method, url, data=data, params=params, files=files, headers=headers\n",
    "            )\n",
    "\n",
    "        if response.status_code in [200, 201, 204]:\n",
    "            return response.json() if response.content else None\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"API request failed: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    # Video endpoints\n",
    "    def list_videos(self, params=None):\n",
    "        \"\"\"\n",
    "        Retrieves a list of videos from the API\n",
    "        \n",
    "        Args:\n",
    "            params (dict, optional): Query parameters to filter the video list\n",
    "            \n",
    "        Returns:\n",
    "            dict: Response from the API containing video data\n",
    "        \"\"\"\n",
    "        return self._make_request(\"GET\", \"/videos\", params=params)\n",
    "\n",
    "    def create_video(self, data):\n",
    "        return self._make_request(\"POST\", \"/videos\", data=data)\n",
    "\n",
    "    def get_video(self, video_id):\n",
    "        return self._make_request(\"GET\", f\"/videos/{video_id}\")\n",
    "\n",
    "    def update_video(self, video_id, data):\n",
    "        return self._make_request(\"PATCH\", f\"/videos/{video_id}\", data=data)\n",
    "\n",
    "    def delete_video(self, video_id):\n",
    "        return self._make_request(\"DELETE\", f\"/videos/{video_id}\")\n",
    "\n",
    "    def upload_video(self, video_id, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\n",
    "                \"POST\", f\"/videos/{video_id}/source\", files={\"file\": file}\n",
    "            )\n",
    "\n",
    "    # Live stream endpoints\n",
    "    def create_live_stream(self, data):\n",
    "        return self._make_request(\"POST\", \"/live-streams\", data=data)\n",
    "\n",
    "    def get_live_stream(self, live_stream_id):\n",
    "        return self._make_request(\"GET\", f\"/live-streams/{live_stream_id}\")\n",
    "\n",
    "    def update_live_stream(self, live_stream_id, data):\n",
    "        return self._make_request(\"PATCH\", f\"/live-streams/{live_stream_id}\", data=data)\n",
    "\n",
    "    def delete_live_stream(self, live_stream_id):\n",
    "        return self._make_request(\"DELETE\", f\"/live-streams/{live_stream_id}\")\n",
    "\n",
    "    # Player endpoints\n",
    "    def create_player(self, data):\n",
    "        return self._make_request(\"POST\", \"/players\", data=data)\n",
    "\n",
    "    def get_player(self, player_id):\n",
    "        return self._make_request(\"GET\", f\"/players/{player_id}\")\n",
    "\n",
    "    def update_player(self, player_id, data):\n",
    "        return self._make_request(\"PATCH\", f\"/players/{player_id}\", data=data)\n",
    "\n",
    "    def delete_player(self, player_id):\n",
    "        return self._make_request(\"DELETE\", f\"/players/{player_id}\")\n",
    "\n",
    "    # Captions endpoints\n",
    "    def upload_caption(self, video_id, language, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\n",
    "                \"POST\", f\"/videos/{video_id}/captions/{language}\", files={\"file\": file}\n",
    "            )\n",
    "\n",
    "    def get_caption(self, video_id, language):\n",
    "        return self._make_request(\"GET\", f\"/videos/{video_id}/captions/{language}\")\n",
    "\n",
    "    def update_caption(self, video_id, language, data):\n",
    "        return self._make_request(\n",
    "            \"PATCH\", f\"/videos/{video_id}/captions/{language}\", data=data\n",
    "        )\n",
    "\n",
    "    def delete_caption(self, video_id, language):\n",
    "        return self._make_request(\"DELETE\", f\"/videos/{video_id}/captions/{language}\")\n",
    "\n",
    "    # Chapters endpoints\n",
    "    def upload_chapter(self, video_id, language, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\n",
    "                \"POST\", f\"/videos/{video_id}/chapters/{language}\", files={\"file\": file}\n",
    "            )\n",
    "\n",
    "    def get_chapter(self, video_id, language):\n",
    "        return self._make_request(\"GET\", f\"/videos/{video_id}/chapters/{language}\")\n",
    "\n",
    "    def delete_chapter(self, video_id, language):\n",
    "        return self._make_request(\"DELETE\", f\"/videos/{video_id}/chapters/{language}\")\n",
    "\n",
    "    # Watermark endpoints\n",
    "    def upload_watermark(self, file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return self._make_request(\"POST\", \"/watermarks\", files={\"file\": file})\n",
    "\n",
    "    def delete_watermark(self, watermark_id):\n",
    "        return self._make_request(\"DELETE\", f\"/watermarks/{watermark_id}\")\n",
    "\n",
    "    # Analytics endpoints\n",
    "    def get_video_analytics(self, video_id, params=None):\n",
    "        return self._make_request(\"GET\", f\"/analytics/videos/{video_id}\", params=params)\n",
    "\n",
    "    def get_live_stream_analytics(self, live_stream_id, params=None):\n",
    "        return self._make_request(\n",
    "            \"GET\", f\"/analytics/live-streams/{live_stream_id}\", params=params\n",
    "        )\n",
    "\n",
    "    # Helper functions\n",
    "    def get_all_videos_for_person(self, person_names):\n",
    "        tags = person_names if isinstance(person_names, list) else [person_names]\n",
    "        return self.list_videos(params={\"tags\": tags})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTTUtils:\n",
    "    @staticmethod\n",
    "    def parse_timestamp(timestamp):\n",
    "        \"\"\"\n",
    "        Parses a timestamp string and returns the total number of seconds.\n",
    "        \n",
    "        Supported formats:\n",
    "        - mm:ss.xxx\n",
    "        - hh:mm:ss.xxx\n",
    "        \n",
    "        Args:\n",
    "            timestamp (str): The timestamp string to parse.\n",
    "            \n",
    "        Returns:\n",
    "            float: Total seconds represented by the timestamp.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the timestamp format is invalid.\n",
    "        \"\"\"\n",
    "        parts = str(timestamp).split(':')\n",
    "        \n",
    "        if len(parts) == 2:\n",
    "            minutes, seconds = parts\n",
    "            hours = 0\n",
    "        elif len(parts) == 3:\n",
    "            hours, minutes, seconds = parts\n",
    "        else: # Ghetto Fallback Mechanism\n",
    "            seconds = 0\n",
    "            minutes = 0 \n",
    "            hours = 99\n",
    "        \n",
    "        try:\n",
    "            total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Invalid numerical values in timestamp.\")\n",
    "        \n",
    "        return total_seconds\n",
    "\n",
    "def extract_segments_by_ids(vtt_content, start_segment_id, end_segment_id):\n",
    "    # Split the VTT content by double newlines to separate individual segments\n",
    "    segments = vtt_content.strip().split(\"\\n\\n\")\n",
    "    \n",
    "    # Initialize a list to hold relevant segments\n",
    "    relevant_segments = []\n",
    "    \n",
    "    # Loop through each segment and process it\n",
    "    for segment in segments:\n",
    "        # Split the segment into lines (ID, timestamp, content)\n",
    "        lines = segment.split(\"\\n\")\n",
    "        \n",
    "        # The first line is the segment ID, convert it to integer\n",
    "        try:\n",
    "            segment_id = int(lines[0].strip())\n",
    "        except ValueError:\n",
    "            # In case the first line is not a segment ID, skip this segment\n",
    "            continue\n",
    "        \n",
    "        # Check if the segment ID is within the desired range\n",
    "        if start_segment_id <= segment_id <= end_segment_id:\n",
    "            relevant_segments.append(segment)\n",
    "    \n",
    "    # Join the relevant segments back together\n",
    "    return \"\\n\\n\".join(relevant_segments)\n",
    "\n",
    "def get_caption_text(video_id):\n",
    "    api_video = ApiVideoAuth(os.getenv(\"API_VIDEO_API_KEY\"))\n",
    "    api_video.authenticate()\n",
    "\n",
    "    openai = OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    video = api_video.get_video(video_id)\n",
    "\n",
    "    caption = api_video.get_caption(video[\"videoId\"], \"en\")\n",
    "    caption_url = caption['src']\n",
    "    response = requests.get(caption_url)\n",
    "    response.raise_for_status()\n",
    "    caption_text = response.text\n",
    "    time.sleep(3) # Sleep for 3 seconds\n",
    "\n",
    "    return caption_text\n",
    "\n",
    "def load_nrc_vad_lexicon(filepath):\n",
    "    vad_lexicon = {}  # Initialize the dictionary\n",
    "    df = pd.read_csv(filepath)\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['word']\n",
    "        vad_lexicon[word] = {\n",
    "            'valence': 2 * row['valence'] - 1,  # Scaling to -1 to 1\n",
    "            'arousal': 2 * row['arousal'] - 1,  # Scaling to -1 to 1\n",
    "            'dominance': 2 * row['dominance'] - 1  # Scaling to -1 to 1\n",
    "        }\n",
    "    return vad_lexicon\n",
    "\n",
    "def parse_vtt_to_df(content, video_id):\n",
    "    blocks = re.split(r'\\n\\s*\\n', content)\n",
    "    data = []\n",
    "\n",
    "    for block in blocks[1:]:  # Skip the WEBVTT and X-TIMESTAMP-MAP headers\n",
    "        lines = block.strip().split('\\n')\n",
    "        if len(lines) >= 3:  # Ensure we have at least index, timing, and text\n",
    "            index = int(lines[0])\n",
    "            timing = lines[1]\n",
    "            text = ' '.join(lines[2:])\n",
    "            \n",
    "              # Extract speaker from the text\n",
    "            match = re.match(r'<v ([^>]+)>(.*)', text)\n",
    "            if match:\n",
    "                speaker, text = match.groups()\n",
    "            else:\n",
    "                speaker = \"\"\n",
    "                \n",
    "            # Extract start and end times\n",
    "            start, end = timing.split(' --> ')\n",
    "\n",
    "            data.append({\n",
    "                'video_id': video_id, \n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'speaker': speaker,\n",
    "                'text': text,\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def combine_consecutive_speakers(df):\n",
    "        df['speaker_changed'] = df['speaker'] != df['speaker'].shift()\n",
    "        df['group'] = df['speaker_changed'].cumsum()\n",
    "        \n",
    "        result = df.groupby('group').agg({\n",
    "            'video_id': 'first',\n",
    "            'start': 'first',\n",
    "            'end': 'last',\n",
    "            'speaker': 'first',\n",
    "            'text': ' '.join\n",
    "        }).reset_index(drop=True)\n",
    "        \n",
    "        result['index'] = range(0, len(result))\n",
    "        result = result[['video_id','index','start','end','speaker','text']]\n",
    "        return result\n",
    "\n",
    "def calculate_duration(row):\n",
    "    start = row['start'] \n",
    "    end = row['end']\n",
    "\n",
    "    parts_start = start.split(':')\n",
    "    if len(parts_start) == 2:\n",
    "        minutes, seconds = parts_start\n",
    "        hours = 0\n",
    "    elif len(parts_start) == 3:\n",
    "        hours, minutes, seconds = parts_start\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
    "\n",
    "    seconds, milliseconds = seconds.split('.')\n",
    "    \n",
    "    total_seconds_start = (int(hours) * 3600 + int(minutes) * 60 + int(seconds) +\n",
    "                     int(milliseconds) / 1000)\n",
    "\n",
    "    parts_end = end.split(':')\n",
    "    if len(parts_end) == 2:\n",
    "        minutes, seconds = parts_end\n",
    "        hours = 0\n",
    "    elif len(parts_end) == 3:\n",
    "        hours, minutes, seconds = parts_end\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
    "\n",
    "    seconds, milliseconds = seconds.split('.')\n",
    "    \n",
    "    total_seconds_end = (int(hours) * 3600 + int(minutes) * 60 + int(seconds) +\n",
    "                     int(milliseconds) / 1000)\n",
    "\n",
    "    duration = total_seconds_end - total_seconds_start\n",
    "\n",
    "    return duration\n",
    "\n",
    "def count_words(text):\n",
    "    words = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    return len(words)\n",
    "\n",
    "def calculate_wpm(row):\n",
    "    # Avoid division by zero\n",
    "    if row['duration'] == 0:\n",
    "        return 0\n",
    "    # Convert duration to minutes and calculate WPM\n",
    "    return (row['word_count'] / (row['duration'] / 60))\n",
    "\n",
    "def comprehensive_text_analysis(text):\n",
    "    # Word count\n",
    "    words = re.findall(r\"\\b[a-z']+\\b\", text.lower())\n",
    "    word_count = len(words)\n",
    "\n",
    "    # Filler words and profanity\n",
    "    hard_filler_words = set(['um', 'uh'])\n",
    "    soft_filler_words = set(['like', 'you know', 'well', 'so', 'just', \n",
    "                        'kind of', 'sort of', 'i mean', 'basically', 'actually', \n",
    "                        'literally', 'honestly'])\n",
    "    profanities = set(['damn', 'hell', 'shit', 'fuck', 'ass', 'bitch', 'bullshit'])\n",
    "\n",
    "    hard_filler_count = sum(1 for word in words if word in hard_filler_words)\n",
    "    soft_filler_count = sum(1 for word in words if word in soft_filler_words)\n",
    "    profanity_count = sum(1 for word in words if word in profanities)\n",
    "\n",
    "    # Question and sentence count\n",
    "    question_count = text.count('?')\n",
    "    sentence_count = len(re.findall(r'\\w+[.!?]', text))\n",
    "\n",
    "    return {\n",
    "        'word_count': word_count,\n",
    "        'hard_filler_count': hard_filler_count,\n",
    "        'soft_filler_count': soft_filler_count,\n",
    "        'profanity_count': profanity_count,\n",
    "        'question_count': question_count,\n",
    "        'sentence_count': sentence_count\n",
    "    }\n",
    "\n",
    "def calculate_vad_scores(text):\n",
    "    words = re.findall(r\"\\b[a-z']+\\b\", text.lower())\n",
    "    total_valence = total_arousal = total_dominance = word_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in vad_lexicon:\n",
    "            scores = vad_lexicon[word]\n",
    "            total_valence += scores['valence']\n",
    "            total_arousal += scores['arousal']\n",
    "            total_dominance += scores['dominance']\n",
    "            word_count += 1\n",
    "\n",
    "    # Calculate average VAD scores for the subtitle\n",
    "    if word_count > 0:\n",
    "        avg_valence = total_valence / word_count\n",
    "        avg_arousal = total_arousal / word_count\n",
    "        avg_dominance = total_dominance / word_count\n",
    "    else:\n",
    "        avg_valence = avg_arousal = avg_dominance = None  # No valid VAD words\n",
    "\n",
    "    return {\n",
    "        'avg_valence': avg_valence,\n",
    "        'avg_arousal': avg_arousal,\n",
    "        'avg_dominance': avg_dominance,\n",
    "        'total_valence': total_valence,\n",
    "        'total_arousal': total_arousal,\n",
    "        'total_dominance': total_dominance,\n",
    "        'vad_word_count': word_count\n",
    "    }\n",
    "\n",
    "def enrich_clean_vtt_df(df):\n",
    "    df['duration'] = df.apply(calculate_duration, axis=1)\n",
    "    \n",
    "    # Apply the comprehensive text analysis function\n",
    "    analysis_results = df['text'].apply(comprehensive_text_analysis)\n",
    "    \n",
    "    # Add new columns based on the analysis results\n",
    "    for key in ['word_count', 'hard_filler_count', 'soft_filler_count', \n",
    "                'profanity_count', 'question_count', 'sentence_count']:\n",
    "        df[key] = analysis_results.apply(lambda x: x[key])\n",
    "    \n",
    "    # Calculate VAD scores separately using the original 'text' column\n",
    "    vad_results = df['text'].apply(calculate_vad_scores)\n",
    "    \n",
    "    # Add VAD-related columns\n",
    "    for key in ['avg_valence', 'avg_arousal', 'avg_dominance', \n",
    "                'total_valence', 'total_arousal', 'total_dominance', 'vad_word_count']:\n",
    "        df[key] = vad_results.apply(lambda x: x[key])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_clean_vtt(video_id):\n",
    "    raw_vtt = get_caption_text(video_id)\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    df = combine_consecutive_speakers(vtt_in_df)\n",
    "\n",
    "    vtt_content = \"WEBVTT\\n\\n\"  # VTT header\n",
    "    segment_id = 0\n",
    "    for _, row in df.iterrows():\n",
    "        # Format timestamp\n",
    "        start_time = row['start']\n",
    "        end_time = row['end']\n",
    "        timestamp = f\"{start_time} --> {end_time}\"\n",
    "        \n",
    "        # Format speaker and text\n",
    "        speaker = f\"<v {row['speaker']}>\"\n",
    "        text = row['text']\n",
    "        \n",
    "        # Combine into VTT format\n",
    "        vtt_content += f\"{segment_id}\\n{timestamp}\\n{speaker} {text}\\n\\n\"\n",
    "        segment_id= segment_id + 1\n",
    "    return vtt_content\n",
    "\n",
    "def get_meeting_summary(clean, speaker):\n",
    "\n",
    "    target_person = speaker\n",
    "    caption_text = clean\n",
    "\n",
    "    ## Adjusted prompt, based on requirement that 3 outputs are required\n",
    "    prompt = f\"\"\"\n",
    "        You are an expert in analyzing communication transcripts to summarize the content of a meeting. You need to provide three outputs, on three separate lines. \n",
    "        1) What type of meeting is this? (e.g. 1 on 1, team meeting, all-hands)\n",
    "        2) Provide a two - three sententence summary of what the meeting is about. Use names and be specific as possible. Begin with \"In this meeting\"\n",
    "        3) What role did {target_person} play in this meeting? Provide a two - three sententences\n",
    "        OUPUT: \n",
    "        Meeting Type: ...\n",
    "        Meeting Summary: In this meeting... \n",
    "        Target Role: In this meeting {target_person}... \n",
    "    \"\"\"\n",
    "\n",
    "    # Send prompt and caption text to OpenAI for processing\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{prompt}\\n\\n{caption_text}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Extract response from the OpenAI completion\n",
    "    meeting_summary = chat_completion.choices[0].message.content\n",
    "    return meeting_summary\n",
    "\n",
    "def get_vtt_df(video_id):\n",
    "    raw_vtt = get_clean_vtt(video_id)\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    df = combine_consecutive_speakers(vtt_in_df)\n",
    "    return df\n",
    "\n",
    "def build_clean_vtt_adjust(raw, video_id):\n",
    "    raw_vtt = raw\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    df = combine_consecutive_speakers(vtt_in_df)\n",
    "\n",
    "    vtt_content = \"WEBVTT\\n\\n\"  # VTT header\n",
    "    segment_id = 0\n",
    "    for _, row in df.iterrows():\n",
    "        # Format timestamp\n",
    "        start_time = row['start']\n",
    "        end_time = row['end']\n",
    "        timestamp = f\"{start_time} --> {end_time}\"\n",
    "        \n",
    "        # Format speaker and text\n",
    "        speaker = f\"<v {row['speaker']}>\"\n",
    "        text = row['text']\n",
    "        \n",
    "        # Combine into VTT format\n",
    "        vtt_content += f\"{segment_id}\\n{timestamp}\\n{speaker} {text}\\n\\n\"\n",
    "        segment_id= segment_id + 1\n",
    "    return vtt_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Inputs for \n",
    "activity_max = \"5\"\n",
    "sequence_max = \"20\"\n",
    "sequence_min = \"5\"\n",
    "activity_name = \"\"\n",
    "prompt_mission = \"\"\n",
    "agent_detection_prompt = \"\"\n",
    "sublabel_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "    \n",
    "    activity_name = \"Feedback\" \n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "        Your task is to identify / detect sequences of segments in the transcript where the participants give feedback.\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, whose job is to analyze communication transcripts. You will be provided a transcript in VTT format. It is a live recording of a meeting with multiple participants.\n",
    "        \n",
    "        Your task is to correctly assess if {target_person} is either giving feedback, recieving feedback, or not involved. Provide a rational for what you believe the answer is then answer giving feedback if {target_person} is the primary person giving feedback and answer recieving if you believe someone else is the primary person giving feedback. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "        - Giving Feedback: {target_person} is giving feedback to someone about something. This can include constructive feedback, positive reinforcement, guidence, or suggestions about ways to improve performance, a work product, teamm, or initiative.\n",
    "        - Receiving Feedback: {target_person} is reciving feedback from someone about something. This can include constructive feedback, positive reinforcement, guidence, or suggestions about ways to improve performance, a work product, teamm, or initiative.\n",
    "        - Not Involved: {target_person} is not involved in the interaction\n",
    "        - Not Feedback: The interaction is not considered feedback at all.\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Giving Feedback\",\n",
    "                \"reasoning\": \"{target_person} is the primary person giving feedback in this case because they directly state 'I think you need to write out your thinking first then you can think more clearly' which indicates they are the primary actor in this transcript.\",\n",
    "            }}\n",
    "\n",
    "        Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, whose job is to analyze communication transcripts. World peace is at stake. \n",
    "        You will be provided a summary of a moment that occured within a meeting and then the transcript in VTT format from that moment. You will also be given the directionality of feedback in a JSON. It is a live recording of a meeting with multiple participants. \n",
    "\n",
    "        If the JSON input says 'Giving Feedback' then {target_person} is giving someone else feedback. If the JSON input is 'Receiving Feedback' then {target_person} is receiving feedback from someone else. Any other input means this is 'Not Feedback'\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript, and provide the result in JSON format with two fields: 'type' and 'reasoning'.\n",
    "\n",
    "        Categories:\n",
    "        1.\tPositive Reinforcement: [Someone is affirming or encouraging anothers actions, behaviors, or performance to reinforce positive outcomes]\n",
    "        2.\tConstructive Feedback: [Someone is offering specific, actionable suggestions for improvement to something within the other persons control (e.g., work, performance)]\n",
    "        3.\tCritical Feedback: [Someone is pointing out negative or problematic behavior directly related to the person they are addressing.]\n",
    "        4.\tGuidance: [Someone is offering advice, support, or direction to help another solve a problem, improve, or grow.]\n",
    "        5.\tSuggestion: [Someone is proposing a new or alternative way of doing something, without directly offering criticism.]\n",
    "        6.\tRequest: [Someone is asking or instructing another to complete a task, provide information, or take action.]\n",
    "        7.\tOther Feedback: [The communication does not fit into any of the feedback categories but is considered feedback]\n",
    "        8. Not Feedback: [The communication does not fit into any of the feedback categories and is not considered feedback e.g., general conversation, unrelated comments)]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Positive Reinforcement\",\n",
    "                \"reasoning\": \"Person1 offered positive feedback Person2: 'I like what you did there' during the transcript.\",\n",
    "            }}\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delegation_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name = \"Delegation\" \n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "        Your task is to identify / detect sequences of segments in the transcript where the participants delegate to eachother.\n",
    "\n",
    "        Some potential signs to look for in the transcript to identify delegation include but are not limited to:\n",
    "\t        1.\tTask Assignment: One person directs another to complete a task (e.g., “Can you handle this?”).\n",
    "\t        2.\tAuthority Transfer: Responsibility or decision-making power is given (e.g., “You can decide on this”).\n",
    "\t        3.\tAccountability: The delegatee is made responsible for the outcome (e.g., “I am counting on you for this”).\n",
    "\t        4.\tSupport Offered: Guidance or resources may be provided (e.g., “Let me know if you need help”).\n",
    "\t        5.\tTimeline: Deadlines or expectations are set (e.g., “Complete this by Friday”).\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is delegating, receiving a delegated task, or not involved. Provide reasoning for your assessment and answer with delegating if {target_person} is the one delegating the task, receiving if they are being delegated a task, or no delegation if neither applies. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "        •\tDelegating: {target_person} is delegating something to another person.\n",
    "        •\tReceiving: {target_person} is being delegated to by someone else.\n",
    "        •\tNot Involved: {target_person} is not involved in the interaction.\n",
    "        •\tNo Delegation: The interaction does not involve delegation.\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Delegating\",\n",
    "                \"reasoning\": \"{target_person} is the primary person delegating because they say 'Can you handle this by Friday?' indicating task assignment.\"\n",
    "            }}\n",
    "\n",
    "        Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the directionality of delegation in a JSON. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        If the JSON input says ‘Delegating’ then {target_person} is delegating a task or responsibility to someone else. If the input says ‘Receiving’ then {target_person} is being assigned a task or responsibility. Any other input means this is ‘Not Delegation’ \n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript, and provide the result in JSON format with two fields: ‘type’ and ‘reasoning’\n",
    "\n",
    "        Categories:\n",
    "\n",
    "            1.\tTask Assignment: [Someone is assigning a specific task or responsibility to another person.]\n",
    "            2.\tGuidance with Delegation: [Someone is offering advice or support along with assigning a task to help the person succeed.]\n",
    "            3.\tRequest for Action: [Someone is asking another person to take action or provide something, but not explicitly assigning a task.]\n",
    "            4.\tAuthority Transfer: [Someone is giving another person decision-making authority over a specific task or responsibility.]\n",
    "            5.\tReceiving Delegation: [Someone is receiving a task, responsibility, or authority from another person.]\n",
    "            6.\tOther Delegation: [The communication involves delegation but does not clearly fit into the above categories.]\n",
    "            7.\tNot Delegation: [The communication does not involve delegation, e.g., unrelated conversation or general discussion.]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Task Assignment\",\n",
    "                \"reasoning\": \"{target_person} is delegating by saying, 'Can you handle this report by tomorrow?' which assigns a task.\"\n",
    "            }}\n",
    "\n",
    "        OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_making_prompt_builder(target_person):\n",
    "    target_person =target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name = \"Decision Making\" \n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "       Your task is to identify / detect sequences of segments in the transcript where the participants are attempting to to make a decision, either successful or unsuccessful.\n",
    "       Some potential signs to look for in the transcript to identify delegation include but are not limited to:\n",
    "        1.\tProblem or Opportunity Identification: A challenge or opportunity is raised, based on external or internal factors, framed around strategic goals.\n",
    "        2.\tFraming and Context Setting: The issue is outlined with relevant data, risks, and timelines to provide clarity for the decision-making process.\n",
    "        3.\tDiscussion and Input Gathering: Input is gathered from team members, with a focus on options, priorities, and strategic alignment.\n",
    "        4.\tOptions Evaluation: The team evaluates different paths, weighing risks, costs, and strategic fit, possibly facing competing priorities.\n",
    "        5.\tDecision Ownership: One individual (e.g., CEO or leader) takes responsibility for making the final call, based on the input gathered.\n",
    "        6.\tConsensus or Alignment Building: The decision-maker works to get team alignment, ensuring key stakeholders support the decision, whether this succeeds or not.\n",
    "        7.\tActionable Decision: A decision is made, with clear steps and ownership assigned for execution. Success or failure depends on team alignment and execution..\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is participating in the decision-making process or not. Provide reasoning for your assessment and answer with Participating if {target_person} is actively engaged in the decision-making process or Not Participating if they are not involved. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "\n",
    "            •\tParticipating: {target_person} is actively contributing to the decision-making process by giving input, discussing options, or influencing the outcome.\n",
    "            •\tNot Participating: {target_person} is not involved in the decision-making process during this interaction.\n",
    "\n",
    "\n",
    "            Example Output:\n",
    "                {{\n",
    "                    \"type\": \"Participating\",\n",
    "                    \"reasoning\": \"{target_person} provided input on the options being discussed, contributing to the decision-making.\"\n",
    "                }}\n",
    "\n",
    "            Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "            OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the decision-making context in a JSON input. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript and provide the result in JSON format with two fields: ‘type’ and ‘reasoning.’\n",
    "\n",
    "        Categories:\n",
    "\n",
    "            1.\tProblem or Opportunity Identification: [Someone identifies a challenge or opportunity that needs attention, often based on external (market/customer) or internal (performance/resources) factors.]\n",
    "            2.\tFraming and Context Setting: [The issue is explained with data, risks, or timelines, helping the team understand the scope of the decision.]\n",
    "            3.\tDiscussion and Input Gathering: [Input from multiple team members is sought, and the group discusses options, priorities, and trade-offs.]\n",
    "            4.\tOptions Evaluation: [The team evaluates different paths, weighing risks, costs, and strategic alignment. Competing priorities may emerge.]\n",
    "            5.\tDecision Ownership: [One person takes responsibility for the final decision, based on input from the team.]\n",
    "            6.\tConsensus or Alignment Building: [The decision-maker works to get alignment from key stakeholders, ensuring the team is on board with the outcome.]\n",
    "            7.\tActionable Decision: [A final, clear decision is made with steps, timelines, and ownership defined for execution.]\n",
    "            8.\tNot Decision-Making: [The communication does not involve decision-making, e.g., general conversation or unrelated comments.]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Task Assignment\",\n",
    "                \"reasoning\": \"{target_person} is delegating by saying, 'Can you handle this report by tomorrow?' which assigns a task.\"\n",
    "            }}\n",
    "            \n",
    "         OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motivation_prompt_builder(target_person):\n",
    "    target_person = target_person\n",
    "    global activity_name\n",
    "    global prompt_mission\n",
    "    global agent_detection_prompt\n",
    "    global sublabel_prompt\n",
    "\n",
    "    activity_name =\"Dave\"\n",
    "\n",
    "    prompt_mission = \"\"\"\n",
    "    Your task is to identify / detect sequences of segments in the transcript where the participants are attempting to motivate or inpsire others. Look for these key indicators that someone is trying to motivate or inspire:\n",
    "\n",
    "1. Vision Casting: Painting a compelling picture of future possibilities or positive outcomes, often using vivid language and emotional appeals to help others see what could be achieved.\n",
    "\n",
    "2. Belief Reinforcement: Expressing confidence in others' abilities, highlighting their past successes, or acknowledging their potential to achieve goals.\n",
    "\n",
    "3. Purpose Emphasis: Connecting tasks or goals to larger meaningful impacts, whether for the team, organization, customers, or society.\n",
    "\n",
    "4. Growth Mindset Activation: Reframing challenges as learning opportunities, encouraging resilience, or emphasizing that abilities can be developed through effort.\n",
    "\n",
    "5. Energy Building: Using dynamic language, enthusiasm, or call-and-response patterns to create positive emotional energy and collective momentum.\n",
    "\n",
    "When reviewing the transcript, note that motivation attempts may combine multiple indicators and can range from brief encouraging statements to extended inspirational messages.\n",
    "        \"\"\"\n",
    "\n",
    "    agent_detection_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. You will be provided a transcript in VTT format from a live meeting with multiple participants. Your task is to assess if {target_person} is activly inspiring or motivating others. Provide reasoning for your assessment and answer with Participating if {target_person} is actively engaged in inspiring or motivating others process or Not Participating if they are not involved. Answer with no additional information.\n",
    "\n",
    "        Type Options and Definitions:\n",
    "\n",
    "            •\tParticipating: {target_person} is actively inspiring or motivating others.\n",
    "            •\tNot Participating: {target_person} is receiving inpiration or motivation from other, or not at all.\n",
    "\n",
    "\n",
    "            Example Output:\n",
    "                {{\n",
    "                    \"type\": \"Participating\",\n",
    "                      \"reasoning\": \"{target_person} expressed confidence in others' abilities, highlighting their past successes, or acknowledging their potential to achieve goals to motivate and inspire\"\n",
    "                }}\n",
    "\n",
    "            Do not explain yourself, do not deviate from the format, do not output additional data points.\n",
    "\n",
    "            OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "\n",
    "    sublabel_prompt = f\"\"\"\n",
    "        You are an expert linguist, analyzing communication transcripts. World peace is at stake. You will be provided a summary of a moment that occurred within a meeting and then the transcript in VTT format from that moment. You will also be given the decision-making context in a JSON input. It is a live recording of a meeting with multiple participants.\n",
    "\n",
    "        Your task is to label each segment based on the category it most aligns with using the VTT transcript and provide the result in JSON format with two fields: ‘type’ and ‘reasoning.’\n",
    "\n",
    "        Categories:\n",
    "\n",
    "          1. Vision Casting: [Speaker inspires through vivid descriptions of future possibilities or positive outcomes, using emotional appeals and compelling language to help others envision what could be achieved.]\n",
    "          2. Belief Reinforcement: [Speaker builds confidence by explicitly acknowledging others' abilities, highlighting past successes, or emphasizing their potential to achieve goals.]\n",
    "          3. Purpose Emphasis: [Speaker creates motivation by connecting immediate tasks or goals to larger meaningful impacts for the team, organization, customers, or society.]\n",
    "          4. Growth Mindset Activation: [Speaker encourages development by reframing challenges as learning opportunities, fostering resilience, and emphasizing that abilities can be developed through effort.]\n",
    "          5. Energy Building: [Speaker generates momentum through dynamic language, enthusiasm, or interactive patterns to create positive emotional energy and collective drive.]\n",
    "          6. Not Motivational: [The communication does not involve attempts to motivate or inspire, e.g., purely informational or procedural discussion.]\n",
    "\n",
    "        Example Output:\n",
    "            {{\n",
    "                \"type\": \"Belief Reinforment\",\n",
    "                \"reasoning\": \"{target_person} is motivating and inpsiring by saying, 'We got this, remmeber Q2, we also managed to hit our targets?' which highlights past sucesses.\"\n",
    "            }}\n",
    "            \n",
    "         OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "        \"\"\"\n",
    "    set_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_scheme = \"\"\n",
    "activity_detection_prompt = \"\"\n",
    "\n",
    "vtt_data_structure_example = \"\"\"\n",
    "    {segment_number}\n",
    "    {start_time} --> {end_time}\n",
    "    <v {speaker}>{transcription_content}\n",
    "    \"\"\"\n",
    "\n",
    "def set_templates():\n",
    "  global json_data_scheme\n",
    "  global activity_detection_prompt\n",
    "  json_data_scheme = \"\"\"\n",
    "  {\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"title\": \"Sequence Schema\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"sequence_id\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"A unique identifier for each {activity_name} sequence\"\n",
    "        },\n",
    "        \"segment_id_sequence_start\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The Segment number of the first segment within the identified {activity_name} sequence\"\n",
    "        },\n",
    "        \"segment_id_sequence_end\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The Segment number of the last segment within the identified {activity_name} sequence\"\n",
    "        },\n",
    "        \"summary\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"A brief explanation summarizing the interaction and why it was identified as {activity_name}\"\n",
    "        },\n",
    "        \"title\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"A 4 to 6 word decsriptive for the clip that references the topic dicusussed\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"sequence_id\",\n",
    "        \"segment_id_sequence_start\",\n",
    "        \"segment_id_sequence_end\",\n",
    "        \"summary\"\n",
    "      ],\n",
    "      \"additionalProperties\": false\n",
    "    }\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  # Full Prompt \n",
    "  activity_detection_prompt = f\"\"\"\n",
    "      You are an expert linguist, whose job is to analyze communication transcripts. World peace is at stake.\n",
    "      You will be provided a transcript in VTT format. It is a live recording of a meeting with multiple participants.The VTT contains an array of segments, each representing a portion of the conversation. Here is an example of one such segment, including a description of the key-value pairs:\n",
    "\n",
    "      ```\n",
    "      5\n",
    "      00:24.494 --> 00:30.080\n",
    "      <v William Hayden>And I just want to understand why that is what we can do to make sure that in the future\n",
    "\n",
    "      6\n",
    "      00:31.180 --> 00:36.340\n",
    "      <v William Hayden>we retain top talent because that's like make or break for an organization, especially in this stage.\n",
    "      ```\n",
    "\n",
    "      This VTT transcript contains the following key components:\n",
    "      ```\n",
    "      Segment number: A unique identifier for this portion of the conversation\n",
    "      Timestamp: The time range in which this segment of the conversation occurred\n",
    "      Speaker: The name of the person speaking within angle brackets <v Speaker Name>\n",
    "      Content: The actual text spoken during this segment\n",
    "      ```\n",
    "\n",
    "      ```\n",
    "      {vtt_data_structure_example}\n",
    "      ```\n",
    "      \n",
    "      The full transcript will consist of multiple such segments, each representing a distinct portion of the meeting conversation. These segments, when put together in order, form the complete transcript of the meeting.\n",
    "\n",
    "      {prompt_mission}\n",
    "      \n",
    "      Those sequences must not overlap, meaning the same distinct segment must not be part of multiple sequences of segments where the {activity_name} has been identified / detected. Sequences should include context so someone reading it later can understand the interaction. Additionally, try to avoid very long sequences (no more than {sequence_max}) and very short sequences (no less than {sequence_min}); when the content of the transcript suggests a change of the conversation topic the sequence should end. Those sequences must not overlap.\n",
    "\n",
    "      For each identified sequence of segments, provide the following data points in JSON format. Then, output your final result in a JSON-compatible array:\n",
    "\n",
    "      JSON SCHEMA FOR THE OUTPUT:\n",
    "      ```\n",
    "  {json_data_scheme}\n",
    "      ```\n",
    "\n",
    "\n",
    "      Do not explain yourself, do not deviate from the format, do not output additional datapoints. Limit the number of outputs to a maximum of the {activity_max} most important instances of {activity_name}.\n",
    "\n",
    "      OUTPUT THE JSON OBJECT ONLY. Your output will be passed to `JSON.parse()`. Do not prefix with anything. Absolutely anything, not even ```json\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_detection(video_id):\n",
    "    caption_text =  get_clean_vtt(video_id)\n",
    "\n",
    "    # Send prompt and caption text to OpenAI for processing\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{activity_detection_prompt}\\n\\n{caption_text}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Extract response from the OpenAI completion\n",
    "    activity_detection_response = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Initialize an empty DataFrame for storing enriched subtitles\n",
    "    final_df = pd.DataFrame()\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "    # Assuming activity_detection_response is a JSON string or a list of dictionaries\n",
    "    try:\n",
    "        # Try loading it as JSON\n",
    "        activity_data = pd.read_json(activity_detection_response)\n",
    "    except ValueError:\n",
    "        # If not a valid JSON string, try evaluating it as a list of dictionaries\n",
    "        activity_data = pd.DataFrame(eval(activity_detection_response))\n",
    "\n",
    "    # Create DataFrame with the activity detection data\n",
    "    df_activity_detection = pd.DataFrame(activity_data)\n",
    "    return df_activity_detection\n",
    "\n",
    "def process_row(row):\n",
    "    \n",
    "    start_seq = row[\"segment_id_sequence_start\"]\n",
    "    end_seq = row[\"segment_id_sequence_end\"]\n",
    "    \n",
    "    ## NEED TO FIX CURRENTLY TIMESTAMPS ARE WRONG\n",
    "    vtt_df = get_vtt_df(video_id)\n",
    "    \n",
    "    try:\n",
    "        start_timestamp = vtt_df.loc[vtt_df['index'] == start_seq, 'start'].values[0]\n",
    "    except IndexError:\n",
    "        print(f\"No match found for start_seq {start_seq}\")\n",
    "        start_timestamp = None\n",
    "\n",
    "    try:\n",
    "        end_timestamp = vtt_df.loc[vtt_df['index'] == end_seq, 'end'].values[0]\n",
    "    except IndexError:\n",
    "        end_timestamp = vtt_df.loc[vtt_df['index'] == end_seq-1, 'end'].values[0]\n",
    "    except IndexError:\n",
    "        print(f\"No match found for end_seq {end_seq}\")\n",
    "        end_timestamp = None\n",
    "\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"segment_start_timestamp\": start_timestamp,\n",
    "            \"segment_end_timestamp\": end_timestamp,\n",
    "            \"segment_start_timestamp_in_seconds\": VTTUtils.parse_timestamp(start_timestamp),\n",
    "            \"segment_end_timestamp_in_seconds\": VTTUtils.parse_timestamp(end_timestamp),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def process_activity_detection(df):\n",
    "    df_activity_detection = df\n",
    "    df_activity_detection[[\"segment_start_timestamp\", \"segment_end_timestamp\", \"segment_start_timestamp_in_seconds\", \"segment_end_timestamp_in_seconds\"]] = (\n",
    "        df_activity_detection.apply(process_row, axis=1)\n",
    "    )\n",
    "    return df_activity_detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_activity_detection(df):\n",
    "    final_df = df\n",
    "\n",
    "    # Convert JSON strings in 'activity_analysis' and 'target_person_analysis' to dictionaries\n",
    "    final_df['activity_analysis'] = final_df['activity_analysis'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "    final_df['target_person_analysis'] = final_df['target_person_analysis'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Extract 'type' and 'reasoning' from 'activity_analysis'\n",
    "    final_df['activity_type'] = final_df['activity_analysis'].apply(lambda x: x['type'] if isinstance(x, dict) else None)\n",
    "    final_df['activity_reasoning'] = final_df['activity_analysis'].apply(lambda x: x['reasoning'] if isinstance(x, dict) else None)\n",
    "\n",
    "    # Extract 'type' and 'reasoning' from 'target_person_analysis' (treat as dictionary, not list)\n",
    "    final_df['target_person_type'] = final_df['target_person_analysis'].apply(lambda x: x['type'] if isinstance(x, dict) else None)\n",
    "    final_df['target_person_reasoning'] = final_df['target_person_analysis'].apply(lambda x: x['reasoning'] if isinstance(x, dict) else None)\n",
    "\n",
    "    # Drop the original JSON columns\n",
    "    final_df = final_df.drop(columns=['activity_analysis', 'target_person_analysis'])\n",
    "\n",
    "    # Add a column that is always 'Feedback'\n",
    "    final_df['activity'] = f\"{activity_name}\"\n",
    "\n",
    "    # Convert segment_start_timestamp_in_seconds and segment_end_timestamp_in_seconds to integers\n",
    "    final_df['segment_start_timestamp_in_seconds'] = final_df['segment_start_timestamp_in_seconds'].astype(int)\n",
    "    final_df['segment_end_timestamp_in_seconds'] = final_df['segment_end_timestamp_in_seconds'].astype(int)\n",
    "\n",
    "    # Add 'Moment_url' column based on video_id and segment_start_timestamp_in_seconds\n",
    "    final_df['Moment_url'] = final_df.apply(lambda row: f\"https://embed.api.video/vod/{row['video_id']}#;t={row['segment_start_timestamp_in_seconds']}\", axis=1)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_idsv2():\n",
    "    with apivideo.AuthenticatedApiClient(os.getenv(\"API_VIDEO_API_KEY\")) as api_client:\n",
    "        # Create an instance of the API class\n",
    "        api_instance = videos_api.VideosApi(api_client)\n",
    "        sort_by = \"publishedAt\" # str | Use this parameter to sort videos by the their created time, published time, updated time, or by title. (optional)\n",
    "        sort_order = \"asc\" # str | Use this parameter to sort results. `asc` is ascending and sorts from A to Z. `desc` is descending and sorts from Z to A. (optional)\n",
    "        page_size = 100 # int | Results per page. Allowed values 1-100, default is 25. (optional) if omitted the server will use the default value of 25\n",
    "\n",
    "        # example passing only required values which don't have defaults set\n",
    "        # and optional values\n",
    "        try:\n",
    "            # List all video objects\n",
    "            api_response = api_instance.list(sort_by=sort_by, sort_order=sort_order, page_size=page_size)\n",
    "            #pprint(api_response)\n",
    "        except apivideo.ApiException as e:\n",
    "            print(\"Exception when calling VideosApi->list: %s\\n\" % e)\n",
    "        api_response = api_response.get('data')\n",
    "        video_ids = [item['video_id'] for item in api_response]\n",
    "        return video_ids\n",
    "\n",
    "    return api_response\n",
    "\n",
    "def get_video_object(video_id):\n",
    "    # Enter a context with an instance of the API client\n",
    "    with apivideo.AuthenticatedApiClient(os.getenv(\"API_VIDEO_API_KEY\")) as api_client:\n",
    "        # Create an instance of the API class\n",
    "        api_instance = videos_api.VideosApi(api_client)\n",
    "        video_id = video_id # str | The unique identifier for the video you want details about.\n",
    "\n",
    "        # example passing only required values which don't have defaults set\n",
    "        try:\n",
    "            # Show a video\n",
    "            api_response = api_instance.get(video_id)\n",
    "        except apivideo.ApiException as e:\n",
    "            print(\"Exception when calling VideosApi->get: %s\\n\" % e)\n",
    "    return api_response\n",
    "\n",
    "def get_delta(video_api_current_video_ids):\n",
    "    all_video_ids = video_api_current_video_ids\n",
    "    engine = create_engine(connection_string)\n",
    "    # Run query and get results into a pandas DataFrame\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT video_api_id FROM public.meetings\")\n",
    "        result = connection.execute(query)\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    supabase_current_video_ids = list(df['video_api_id'])\n",
    "    supabase_missing_video_ids = [video for video in all_video_ids if video not in supabase_current_video_ids]\n",
    "    return supabase_missing_video_ids\n",
    "\n",
    "def generate_meeting_table_data(supabase_missing_video_ids):\n",
    "  \n",
    "  if len(supabase_missing_video_ids) > 0:\n",
    "    meetings = []\n",
    "    # Create a list of dictionaries with the required fields\n",
    "    for video_id in supabase_missing_video_ids:\n",
    "        raw_data = get_video_object(video_id)\n",
    "        original_vtt_file = get_caption_text(video_id)\n",
    "        clean_vtt_file = build_clean_vtt_adjust(original_vtt_file, video_id)\n",
    "        summary = get_meeting_summary(clean_vtt_file, video_id)\n",
    "        video_data = {\n",
    "        'video_api_id' : video_id,    \n",
    "        'name' : raw_data.get('title'),\n",
    "        'date' : raw_data.get('published_at'),\n",
    "        'speaker' : raw_data.get('tags')[0],\n",
    "        'original_vtt_file' : original_vtt_file,\n",
    "        'clean_vtt_file' : clean_vtt_file,\n",
    "        'summary' : summary\n",
    "        }\n",
    "        meetings.append(video_data)\n",
    "    meetings = pd.DataFrame(meetings)\n",
    "    return meetings\n",
    "\n",
    "def write_meeting_table_data_to_supabase(data):\n",
    "    meetings = data\n",
    "    try:\n",
    "        # Write DataFrame to PostgreSQL\n",
    "        meetings.to_sql(\n",
    "            'meetings',  # replace with your table name\n",
    "            engine,\n",
    "            if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=1000)\n",
    "        print(\"Data successfully written to database\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        engine.dispose()  # Clean up connection\n",
    "\n",
    "def get_clean_vtt(video_id):\n",
    "    engine = create_engine(connection_string)\n",
    "    # Run query and get results into a pandas DataFrame\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT clean_vtt_file FROM public.meetings WHERE video_api_id = '\" + video_id + \"'\" )\n",
    "        result = connection.execute(query)\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "    # Close connection\n",
    "    engine.dispose()\n",
    "    clean_vtt_file = df['clean_vtt_file']\n",
    "    clean_vtt_file = clean_vtt_file[0]\n",
    "    return clean_vtt_file\n",
    "\n",
    "def update_segments(supabase_missing_video_ids):\n",
    "  \n",
    "  final_df_v2 = pd.DataFrame()\n",
    "  for video_id in supabase_missing_video_ids:\n",
    "    print(f\"Processing video ID: {video_id}\")\n",
    "    raw_vtt = get_clean_vtt(video_id)\n",
    "    vtt_in_df = parse_vtt_to_df(raw_vtt, video_id)\n",
    "    clean_vtt_df = combine_consecutive_speakers(vtt_in_df)\n",
    "    enriched_clean_vtt_df = enrich_clean_vtt_df(clean_vtt_df)\n",
    "\n",
    "    final_df_v2 = pd.concat([final_df_v2, enriched_clean_vtt_df], ignore_index = True)\n",
    "  \n",
    "  print(\"VTT VAD dataset successfully build for all videos\")\n",
    "  \n",
    "  # Your column mapping stays the same\n",
    "  column_mapping = {\n",
    "      'video_id': 'video_api_id',\n",
    "      'start': 'start_timestamp',\n",
    "      'end': 'end_timestamp',\n",
    "      'speaker': 'speaker_name',\n",
    "      'hard_filler_count': \t'hard_filler_word_count',\n",
    "      'soft_filler_count': 'soft_filler_word_count', \t\n",
    "  }\n",
    "  \n",
    "  final_df_v2_renamed = final_df_v2.rename(columns=column_mapping)\n",
    "  \n",
    "  # Create enhancement_id (two approaches you can try):\n",
    "  # Approach 1 - direct UUID objects\n",
    "  final_df_v2_renamed['id'] = final_df_v2_renamed.apply(lambda row: row['video_api_id'] + str(row['index']), axis=1) \n",
    "  \n",
    "  segment_columns = ['id','video_api_id', 'index', 'start_timestamp', \n",
    "                    'end_timestamp', 'text', 'speaker_name', 'word_count', 'sentence_count', 'duration', 'hard_filler_word_count', 'soft_filler_word_count', 'profanity_count', 'question_count', 'vad_word_count', 'total_valence', 'total_arousal', 'total_dominance']\n",
    "  \n",
    "  segments = final_df_v2_renamed\n",
    "  segments = segments[segment_columns]\n",
    "  return segments\n",
    "\n",
    "def write_segements_table_to_supabase(segments):\n",
    "  # Write to database\n",
    "  engine = create_engine(connection_string)\n",
    "  try:\n",
    "      # Write DataFrame to PostgreSQL\n",
    "      segments.to_sql(\n",
    "          'segments',  # replace with your table name\n",
    "          engine,\n",
    "          if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "          index=False,\n",
    "          method='multi',\n",
    "          chunksize=1000  # adjust based on your data size\n",
    "      )\n",
    "      print(\"Data successfully written to database\")\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "  finally:\n",
    "      engine.dispose()  # Clean up connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_moments(df):\n",
    "\n",
    "  moments = df\n",
    "  column_mapping = {\n",
    "      'video_id': 'video_api_id',\n",
    "      'Moment_url': 'moment_url' \t\n",
    "  }\n",
    "  \n",
    "  moments_renamed = moments.rename(columns=column_mapping)\n",
    "  \n",
    "  # Create enhancement_id (two approaches you can try):\n",
    "  # Approach 1 - direct UUID objects\n",
    "  moments_renamed['id'] = [str(uuid.uuid4()) for _ in range(len(moments_renamed))]\n",
    "  moments_renamed['latest'] = 'TRUE'\n",
    "  moments_columns = ['id','segment_id_sequence_start', 'segment_id_sequence_end', 'summary', 'title', 'segment_start_timestamp', 'segment_end_timestamp', 'segment_start_timestamp_in_seconds', 'segment_end_timestamp_in_seconds', 'video_api_id', 'activity_type', 'activity_reasoning', 'target_person_type', 'target_person_reasoning', 'activity', 'moment_url', 'latest']\n",
    "  \n",
    "  \n",
    "  moments_renamed = moments_renamed[moments_columns]\n",
    "  \n",
    "  # Write to database\n",
    "  try:\n",
    "      # Write DataFrame to PostgreSQL\n",
    "      moments_renamed.to_sql(\n",
    "          'moments',  # replace with your table name\n",
    "          engine,\n",
    "          if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "          index=False,\n",
    "          method='multi',\n",
    "          chunksize=1000  # adjust based on your data size\n",
    "      )\n",
    "      print(\"Data successfully written to database\")\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "  finally:\n",
    "      engine.dispose()  # Clean up connection\n",
    "  return moments_renamed\n",
    "\n",
    "def expand_moments_to_segments(moments_df):\n",
    "    \"\"\"\n",
    "    Expands a moments dataframe to create multiple rows for each sequence of segment IDs,\n",
    "    where segment_id is a concatenation of video_api_id and the sequence number.\n",
    "    \n",
    "    Parameters:\n",
    "    moments_df (pd.DataFrame): DataFrame with columns:\n",
    "        - id\n",
    "        - segment_id_sequence_start\n",
    "        - segment_id_sequence_end\n",
    "        - video_api_id\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Expanded DataFrame with columns:\n",
    "        - id (generated sequential ID)\n",
    "        - moments_id (original moment ID)\n",
    "        - segment_id (concatenated video_api_id + sequence number)\n",
    "        - video_api_id\n",
    "    \"\"\"\n",
    "    # Create empty list to store rows\n",
    "    expanded_rows = []\n",
    "    \n",
    "    # Counter for new sequential IDs\n",
    "    current_id = 1\n",
    "    \n",
    "    # Iterate through each moment\n",
    "    for _, row in moments_df.iterrows():\n",
    "        # Generate sequence of segment IDs\n",
    "        segment_numbers = range(\n",
    "            row['segment_id_sequence_start'],\n",
    "            row['segment_id_sequence_end'] + 1\n",
    "        )\n",
    "        \n",
    "        # Create a row for each segment ID\n",
    "        for segment_number in segment_numbers:\n",
    "            # Concatenate video_api_id with segment number\n",
    "            segment_id = f\"{row['video_api_id']}{segment_number}\"\n",
    "            \n",
    "            expanded_rows.append({\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'moments_id': row['id'],\n",
    "                'segment_id': segment_id,\n",
    "                'video_api_id': row['video_api_id']\n",
    "            })\n",
    "            current_id += 1\n",
    "    moments_segment = pd.DataFrame(expanded_rows)\n",
    "    # Create new DataFrame from expanded rows\n",
    "    try:\n",
    "    # Write DataFrame to PostgreSQL\n",
    "      moments_segment.to_sql(\n",
    "          'moments_segment',  # replace with your table name\n",
    "          engine,\n",
    "          if_exists='append',  # 'replace' if you want to overwrite, 'fail' if you want to error if exists\n",
    "          index=False,\n",
    "          method='multi',\n",
    "          chunksize=1000  # adjust based on your data size\n",
    "      )\n",
    "      print(\"Data successfully written to database\")\n",
    "    except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "      engine.dispose()  # Clean up connection\n",
    "    return moments_segment\n",
    "  \n",
    "def mark_old_latest_moment(videoids, activities):\n",
    "   # Update query to set latest=FALSE\n",
    "   query = text(\"UPDATE public.moments SET latest = FALSE WHERE video_api_id IN :videoids AND activity IN :activities AND latest = TRUE\")\n",
    "   print(\"Executing Query on Database: \" + str(query))\n",
    "   \n",
    "   engine = create_engine(connection_string)\n",
    "   \n",
    "   # Run update query with parameters\n",
    "   with engine.connect() as connection:\n",
    "       result = connection.execute(query, {\n",
    "           \"videoids\": tuple(videoids), \n",
    "           \"activities\": tuple(activities)\n",
    "       })\n",
    "       # Commit the transaction\n",
    "       connection.commit()\n",
    "   \n",
    "   # Close connection\n",
    "   engine.dispose()\n",
    "   return result.rowcount  # Returns number of rows updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to database\n",
      "Processing video ID: vi5lUKF5SojsvO2eH5MdSXVs\n",
      "Processing video ID: vi4iA7ftEHA7F7kXxBz5TW1s\n",
      "Processing video ID: vi4Yb16priLky4Ze4x3ApG3C\n",
      "Processing video ID: vi7GkawMp69I47lCmepGg2Y1\n",
      "Processing video ID: vi17iPCCfSCPTTMMwSe8pF4v\n",
      "Processing video ID: vi5oPyx5KnBrR7JX4o3IKRxL\n",
      "Processing video ID: vi5tQVPfxGp8bEIsPrkYLc2t\n",
      "Processing video ID: vimgkWn5yc9eZpob5nXB4k5\n",
      "Processing video ID: vi82EUZk4sRGrV4MBYaYhyr\n",
      "Processing video ID: vi4Ro4yE0PR9xSZ7JKYTU2r6\n",
      "Processing video ID: vi4cHtqlN2qHZYWEcurYLXic\n",
      "Processing video ID: vi2r3uY6mjoU6gc6QjaMcZFk\n",
      "Processing video ID: vi2jqz22wk9sKKz8udDFa4Mv\n",
      "Processing video ID: vi3lhBdLr1b48zymbStBq65m\n",
      "Processing video ID: vi5RzuGHq6hVTXUZ6S2gc5FI\n",
      "Processing video ID: vi1RUWYlkj8srU7xJWhvIgf4\n",
      "Processing video ID: vi3veataLjXlJv4dEEvBGUIS\n",
      "Processing video ID: vi5dVoW7a6py6gDqonevdQhG\n",
      "Processing video ID: vi6izaRPNkne58IZ7zzjofeH\n",
      "Processing video ID: vi4fEA572F2t8znnmHtDUsPu\n",
      "VTT VAD dataset successfully build for all videos\n",
      "Data successfully written to database\n"
     ]
    }
   ],
   "source": [
    "vad_lexicon = load_nrc_vad_lexicon(vad_lexicon_filepath)\n",
    "video_api_current_video_ids = get_video_idsv2()\n",
    "supabase_missing_video_ids = get_delta(video_api_current_video_ids)\n",
    "meetings = generate_meeting_table_data(supabase_missing_video_ids)\n",
    "write_meeting_table_data_to_supabase(meetings)\n",
    "segments = update_segments(supabase_missing_video_ids)\n",
    "write_segements_table_to_supabase(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vi5lUKF5SojsvO2eH5MdSXVs', 'vi4iA7ftEHA7F7kXxBz5TW1s', 'vi4Yb16priLky4Ze4x3ApG3C', 'vi7GkawMp69I47lCmepGg2Y1', 'vi17iPCCfSCPTTMMwSe8pF4v', 'vi5oPyx5KnBrR7JX4o3IKRxL', 'vi5tQVPfxGp8bEIsPrkYLc2t', 'vimgkWn5yc9eZpob5nXB4k5', 'vi82EUZk4sRGrV4MBYaYhyr', 'vi4Ro4yE0PR9xSZ7JKYTU2r6', 'vi4cHtqlN2qHZYWEcurYLXic', 'vi2r3uY6mjoU6gc6QjaMcZFk', 'vi2jqz22wk9sKKz8udDFa4Mv', 'vi3lhBdLr1b48zymbStBq65m', 'vi5RzuGHq6hVTXUZ6S2gc5FI', 'vi1RUWYlkj8srU7xJWhvIgf4', 'vi3veataLjXlJv4dEEvBGUIS', 'vi5dVoW7a6py6gDqonevdQhG', 'vi6izaRPNkne58IZ7zzjofeH', 'vi4fEA572F2t8znnmHtDUsPu']\n"
     ]
    }
   ],
   "source": [
    "print(supabase_missing_video_ids)\n",
    "supabase_missing_video_ids = ['vi5lUKF5SojsvO2eH5MdSXVs', 'vi4iA7ftEHA7F7kXxBz5TW1s', 'vi4Yb16priLky4Ze4x3ApG3C', 'vi7GkawMp69I47lCmepGg2Y1', 'vi17iPCCfSCPTTMMwSe8pF4v', 'vi5oPyx5KnBrR7JX4o3IKRxL', 'vi5tQVPfxGp8bEIsPrkYLc2t', 'vimgkWn5yc9eZpob5nXB4k5', 'vi82EUZk4sRGrV4MBYaYhyr', 'vi4Ro4yE0PR9xSZ7JKYTU2r6', 'vi4cHtqlN2qHZYWEcurYLXic', 'vi2r3uY6mjoU6gc6QjaMcZFk', 'vi2jqz22wk9sKKz8udDFa4Mv', 'vi3lhBdLr1b48zymbStBq65m', 'vi5RzuGHq6hVTXUZ6S2gc5FI', 'vi1RUWYlkj8srU7xJWhvIgf4', 'vi3veataLjXlJv4dEEvBGUIS', 'vi5dVoW7a6py6gDqonevdQhG', 'vi6izaRPNkne58IZ7zzjofeH', 'vi4fEA572F2t8znnmHtDUsPu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_type_selector = [#\"Feedback\",\n",
    "                         # \"Decision Making\",\n",
    "                          \"Delegation\"#,\n",
    "                         #\"Motivation\"\n",
    "  #\"Test\"\n",
    "                         ]\n",
    "\n",
    "## Apply to meeting that have been recently added\n",
    "#ideo_selector = filtered_data\n",
    "video_selector = [{\"videoId\":\"vi19hlTAbN1yu25fpWwdZI70\", \"tags\":[\"Dave McGibbon\"]}]\n",
    "## Apply to meeting that have been recently added\n",
    "\n",
    "#video_selector = [\"vi21tWLEF2GadH1FxBaaUCVv\"]\n",
    "# Initialize ApiVideo and OpenAI instances\n",
    "api_video = ApiVideoAuth(os.getenv(\"API_VIDEO_API_KEY\"))\n",
    "api_video.authenticate()\n",
    "\n",
    "openai = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for video in video_selector:\n",
    "    print(\"Starting Loop\")\n",
    "    target_person = video['tags']\n",
    "    video_id = video['videoId']\n",
    "    video = api_video.get_video(video_id)\n",
    "    caption_text = build_clean_vtt(video_id)\n",
    "\n",
    "    if \"Motivation\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Motivation targeted towards {target_person}\")\n",
    "\n",
    "        motivation_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Feedback\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Feedback targeted towards {target_person}\")\n",
    "\n",
    "        feedback_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Delegation\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Delegation targeted towards {target_person}\")\n",
    "\n",
    "        delegation_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "    if \"Decision Making\" in activity_type_selector:\n",
    "        print(f\"Processing video ID: {video_id}, for Decision Making targeted towards {target_person}\")\n",
    "\n",
    "        decision_making_prompt_builder(target_person)\n",
    "\n",
    "        ## Get activity detection output from video \n",
    "        df_activity_detection = activity_detection(video_id)\n",
    "\n",
    "        ## Add seconds timestamp to the segments\n",
    "        df_activity_detection = process_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Run sublabelling and agent detection \n",
    "        df_activity_detection = agent_detection_sublabeling(df_activity_detection)\n",
    "\n",
    "        ## Format JSON output to columns\n",
    "        final_df_iteration = finalize_activity_detection(df_activity_detection)\n",
    "\n",
    "        ## Append results to final output df\n",
    "        final_df = pd.concat([final_df, final_df_iteration], ignore_index = True)\n",
    "\n",
    "print(\"Video selection has been process for moments activities selection\")\n",
    "final_df.head(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_selector_only_ids = [item['videoId'] for item in video_selector] \n",
    "\n",
    "rows_updated = mark_old_latest_moment(video_selector_only_ids, activity_type_selector)\n",
    "print(f\"Found {rows_updated} old moments and set them to latest = False\")\n",
    "final_df = add_new_moments(final_df)\n",
    "test  = (len(final_df))\n",
    "print(f\"{test} moments data has been added to the database\")\n",
    "print(\"Moments data has been added to the database\")\n",
    "debug = expand_moments_to_segments(final_df)\n",
    "print(\"Moments Segement data has been added to the database\")\n",
    "debug.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test VideoID vi3MC0JsaO4n4cA7cYgYzpb4\n",
    "## vi7hjMrHGRupQnnvk1PmunpJ\n",
    "## vi4flB6clm0iow6IFTbC7emI\n",
    "#filtered_data = update_meetings_table()\n",
    "#if (len(filtered_data) > 0):\n",
    "#  print(\"Building segments for \" + str(len(filtered_data)) + \"...\")\n",
    "#  # update_segments(filtered_data)\n",
    "#else:\n",
    "#  print(\"No new segments build...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
